{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/tf.png\" width=\"128\"/>\n",
    "<img align=\"right\" src=\"images/uu-small.png\" width=\"128\"/>\n",
    "<img align=\"right\" src=\"images/dans.png\" width=\"128\"/>\n",
    "\n",
    "---\n",
    "\n",
    "To get started: consult [start](start.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "# Rings\n",
    "\n",
    "Rings are literary structures of text composition, typically at the sub-sura level.\n",
    "They are marked by certain formal characteristics and a semantic structure where elements at the start\n",
    "are mirrored semantically at the end.\n",
    "The resulting effect is that the crux of the narrative/exposition appears at its center.\n",
    "\n",
    "This is not an easy concept to deal with computationally, because our dataset has only limited semantic information,\n",
    "and the observed patterns are the result of sensitivity of the human mind to a literary and religious text.\n",
    "\n",
    "So, do not expect to a recipe to identify rokings, but just a scratching of their surface.\n",
    "\n",
    "Moreover, this notebook is written from the view-point of a non-expert in Islam and Arabic.\n",
    "It serves as a testimony of how much perception such a person can muster.\n",
    "If you, as an expert, read on, it will become clear how much room for improvement there is.\n",
    "The challenge for you is then to strengthen your computational skills, so that you\n",
    "can actually make those improvements.\n",
    "\n",
    "The notebook finishes off by showing how to save, export and share the data you create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T10:06:39.818664Z",
     "start_time": "2018-05-24T10:06:39.796588Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from tf.app import use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T10:06:51.615044Z",
     "start_time": "2018-05-24T10:06:50.161456Z"
    }
   },
   "outputs": [],
   "source": [
    "A = use('quran', hoist=globals(), check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Exploration\n",
    "\n",
    "We follow an article by\n",
    "Raymond K. Farrin, [*Surat al-Baqara: A Structural Analysis*](https://www.academia.edu/8642515/Surat_al-Baqarah_A_Structural_Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trival detail: names of suras\n",
    "\n",
    "The layman does not know what the Al-Baqara sura is. But there is data!\n",
    "Let's print the names of the suras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in F.otype.s('sura'):\n",
    "  print(f'{F.number.v(s)}: {F.nameTrans.v(s)} ({F.name.v(s)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The article is about sura 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sura2 = F.otype.s('sura')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections\n",
    "\n",
    "The article speaks about sections in sura2.\n",
    "Those sections apparently form a level between the sura and the aya.\n",
    "\n",
    "> The sura, 286 verses, consists of nine sections. \n",
    "\n",
    "```\n",
    "A    1 –  20\n",
    "B   21 –  39\n",
    "C   40 – 103\n",
    "D  104 – 141\n",
    "E  142 – 152\n",
    "􏰁D' 153 – 177\n",
    "C􏰁' 178 – 253\n",
    "B􏰁' 254 – 284\n",
    "A' 285 – 286\n",
    "```\n",
    "\n",
    "Can we identify those sections in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [\n",
    "  (1, 20),\n",
    "  (21, 39),\n",
    "  (40, 103),\n",
    "  (104, 141),\n",
    "  (142, 152),\n",
    "  (153, 177),\n",
    "  (178, 253),\n",
    "  (254, 284),\n",
    "  (285, 286),\n",
    "]\n",
    "\n",
    "nSections = len(sections)\n",
    "sectionStarts = {b for (b, e) in sections}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from suras and ayas, there are other sectional objects in our data, see the \n",
    "feature documentation (one of the links after the incantation):\n",
    "\n",
    "* juz\n",
    "* hizb\n",
    "* manzil\n",
    "* ruku\n",
    "* page\n",
    "* sajda\n",
    "\n",
    "Let's see how our sura is divided into these units.\n",
    "\n",
    "Per unit type we list the how many of those units there are in this sura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTYPES = '''\n",
    "juz\n",
    "hizb\n",
    "manzil\n",
    "ruku\n",
    "page\n",
    "sajda\n",
    "'''.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uType in UTYPES:\n",
    "  units = L.d(sura2, otype=uType)\n",
    "  print(f'{uType.upper():<6}: {len(units):>2} x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to now the exact aya intervals of the hizb, ruku and page units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uType in UTYPES:\n",
    "  units = L.d(sura2, otype=uType)\n",
    "  if not len(units):\n",
    "    continue\n",
    "  print(f'{uType.upper():<6}: {len(units):>2} x')\n",
    "  for unit in units:\n",
    "    unitNum = F.number.v(unit)\n",
    "    ayas = L.d(unit, otype='aya')\n",
    "    firstAya = F.number.v(ayas[0])\n",
    "    lastAya = F.number.v(ayas[-1])\n",
    "    print(f'\\t{unitNum:>2}: aya {firstAya:>3}-{lastAya:>3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the section boundaries all coincide with ruku boundaries.\n",
    "\n",
    "Let's check the degree in which the section boundaries respect the unit boundaries, for each unit type.\n",
    "\n",
    "We collect the start ayas for each unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startAyas = collections.defaultdict(set)\n",
    "\n",
    "for uType in UTYPES:\n",
    "  units = L.d(sura2, otype=uType)\n",
    "  if not len(units):\n",
    "    continue\n",
    "  for unit in units:\n",
    "    unitNum = F.number.v(unit)\n",
    "    ayas = L.d(unit, otype='aya')\n",
    "    firstAya = F.number.v(ayas[0])\n",
    "    startAyas[uType].add(firstAya)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we count how many section starts are members of the startAyas for each unit type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement = {}\n",
    "\n",
    "for uType in UTYPES:\n",
    "  units = L.d(sura2, otype=uType)\n",
    "  if not len(units):\n",
    "    continue\n",
    "  agreement[uType] = len(startAyas[uType] & sectionStarts)\n",
    "  \n",
    "for (uType, agreement) in agreement.items():\n",
    "  print(f'{agreement} out of {nSections} section starts coincide with a {uType} start')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rukus are the best match, but two sections cross a ruku boundary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(sectionStarts - startAyas['ruku'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First and last lines\n",
    "\n",
    "We explore the first and last ayas of each section.\n",
    "\n",
    "We make a list of tuples of their nodes.\n",
    "\n",
    "Note that the number of an aya is not the same as the node number of the aya.\n",
    "\n",
    "Node numbers are like barcodes: they identify objects uniquely within the whole universe.\n",
    "Aya numbers only identify an aya within its sura.\n",
    "But no two ayas have the same node number.\n",
    "\n",
    "All functions of TF require node numbers, so every now and then we have to move from the\n",
    "identifications in front of our nose to the underlying node numbers.\n",
    "\n",
    "That is what the `T.nodeFromSection()` does: it takes a pair (sura number, aya number) and\n",
    "converts it into a unique aya node number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaryAyaNodes = []\n",
    "\n",
    "for (beginAnum, endAnum) in sections:\n",
    "  beginA = T.nodeFromSection((2, beginAnum))\n",
    "  endA = T.nodeFromSection((2, endAnum))\n",
    "  boundaryAyaNodes.append((beginA, endA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the tuple we constructed: an abstract ensemble of barcodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaryAyaNodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we ask TF to show them in a more insightful way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.table(boundaryAyaNodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But I do not read Arabic, and I want to get a sense of what is going on.\n",
    "\n",
    "We display them more extensively by using `A.show()` instead. \n",
    "Before we make the call, we set up a\n",
    "[display parameter](https://annotation.github.io/text-fabric/Api/App/#display)\n",
    "that calls up the `translation@en` feature for each aya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.displaySetup(extraFeatures='translation@en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run `A.show()` now, we get a display of ayas and words with translations and morphological information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.show(boundaryAyaNodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Vocative and resumption particles\n",
    "\n",
    "With my unaided eye I can already see that the start aya tends to start with a vocative particle and the end aya with a resumption particle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build a table of all ayas in this sura, where we highlight first words if they are a resumption or vocative particle.\n",
    "We also highlight the ayas that are the start and end ayas of the sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a tuple of the objects of interest\n",
    "\n",
    "We proceed by building a list of aya nodes and their first words.\n",
    "\n",
    "We also make sets of the ayas where a section starts and where a section ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sura2Ayas = L.d(sura2, otype='aya')\n",
    "\n",
    "ayaTuples = [(a, L.d(a, otype='word')[0]) for a in sura2Ayas]\n",
    "\n",
    "startAyaNodes = set()\n",
    "endAyaNodes = set()\n",
    "\n",
    "for (beginAnum, endAnum) in sections:\n",
    "  beginA = T.nodeFromSection((2, beginAnum))\n",
    "  endA = T.nodeFromSection((2, endAnum))\n",
    "  startAyaNodes.add(beginA)\n",
    "  endAyaNodes.add(endA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining highlights\n",
    "\n",
    "We can make a dictionary of nodes and the colors we want to display their objects in.\n",
    "\n",
    "We can pass that dictionary as a \n",
    "[display parameter](https://annotation.github.io/text-fabric/Api/App/#display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlights = {}\n",
    "\n",
    "for a in sura2Ayas:\n",
    "  firstWord = L.d(a, otype='word')[0]\n",
    "  isVoc = F.posx.v(firstWord) == 'vocative'\n",
    "  isRes = F.posx.v(firstWord) == 'resumption'\n",
    "  if isVoc or isRes:\n",
    "    highlights[firstWord] = 'lime' if isVoc else 'fuchsia'\n",
    "  if a in startAyaNodes:\n",
    "    highlights[a] = 'gold'\n",
    "  elif a in endAyaNodes:\n",
    "    highlights[a] = 'lightcoral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color display of sections and particles\n",
    "\n",
    "Ayas that start a section are marked with a bar in *gold*, the ones that end a section have a *light coral* bar.\n",
    "\n",
    "Resumptive particles at the start of an aya are highlighted in *fuchsia*, the voactive ones in *lime*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.table(ayaTuples, highlights=highlights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Semantics\n",
    "\n",
    "The article says: \n",
    "\n",
    "> interior sections correspond to each other: the second section corresponds to the second-to-last, and so on concentrically.\n",
    "\n",
    "and\n",
    "\n",
    "> By means of concentric patterning, ring composition calls attention to the center. We are drawn to look here for the essential message.\n",
    "\n",
    "If you don't read Arabic, a translation is the next best way to access the semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffled ayas\n",
    "\n",
    "For each section, we will list the first three ayas (b1, b2, b3), the middle three (m1, m2, m3) and the last three (e1, e2, e3).\n",
    "\n",
    "We produce them in the order b1 - e3 - b2 - e2 - b3 - e1 - m1 - m3 - m2.\n",
    "\n",
    "We also put the first words, if they are particles of the vocative or resumption kind in the table.\n",
    "\n",
    "Everything will be formatted in a markdown table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dm(markdownString):\n",
    "  display(Markdown(markdownString))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction of the table\n",
    "\n",
    "We walk through the sections and grab all the information we need, and wrap it into a big\n",
    "markdown table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown = '''\n",
    "section | aya | position | kind | particle | translation\n",
    "--- | --- | --- | --- | --- | ---\n",
    "'''.lstrip()\n",
    "\n",
    "for (i, (beginAnum, endAnum)) in enumerate(sections):\n",
    "  ayas = {}\n",
    "  ayas['b1'] = T.nodeFromSection((2, beginAnum))\n",
    "  ayas['e3'] = T.nodeFromSection((2, endAnum))\n",
    "  ayas['m2'] = (ayas['b1'] + ayas['e3']) // 2\n",
    "  ayas['b2'] = ayas['b1'] + 1\n",
    "  ayas['b3'] = ayas['b1'] + 2\n",
    "  ayas['m1'] = ayas['m2'] - 1\n",
    "  ayas['m3'] = ayas['m2'] + 1\n",
    "  ayas['e1'] = ayas['e3'] - 2\n",
    "  ayas['e2'] = ayas['e3'] - 1\n",
    "  for aName in 'b1 e3 b2 e2 b3 e1 m1 m3 m2'.split():\n",
    "    a = ayas[aName]\n",
    "    w = L.d(a, otype='word')[0]\n",
    "    posx = F.posx.v(w)\n",
    "    kind = posx if posx in {'vocative', 'resumption'} else None\n",
    "    particle = None if kind is None else F.ascii.v(w)\n",
    "    markdown += f'''\n",
    "{i + 1} | {F.number.v(a)} | {aName} | {kind or '&nbsp;'} | {particle or '&nbsp;'} | {Fs('translation@en').v(a)}\n",
    "'''.lstrip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffled table display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Sentiment Mining (primitive)\n",
    "\n",
    "As the article points out, sections often start by speaking to *good* people or actions, and end with condemning *bad*\n",
    "people or actions. Can we base sentiment mining on this idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positivity located in the rings\n",
    "\n",
    "If a verb, noun or adjective occurs in an e1, e2, or e3 aya, its positivity is deccreased by 1, if it occurs in a b1, b2, b3 it is increased by 1.\n",
    "\n",
    "This is very crude, because we have taken the ring structure very rigidly.\n",
    "In the actual text, there might be ayas that are less pertinent to the ring structure, and the middle of the ring \n",
    "does not have to coincide with the exact middle aya of the section.\n",
    "\n",
    "It is up to the expert to devise additional heuristics that help to identify the rings in a more precise mannner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating positivity\n",
    "\n",
    "Now we are going to assign a positivity to all lemmas (verb, noun or adjective) of the sura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positivity = collections.Counter()\n",
    "contentCats = {'verb', 'noun', 'word'}\n",
    "\n",
    "for (i, (beginAnum, endAnum)) in enumerate(sections):\n",
    "  ayas = {}\n",
    "  ayas['b1'] = T.nodeFromSection((2, beginAnum))\n",
    "  ayas['e3'] = T.nodeFromSection((2, endAnum))\n",
    "  ayas['m2'] = (ayas['b1'] + ayas['e3']) // 2\n",
    "  ayas['b2'] = ayas['b1'] + 1\n",
    "  ayas['b3'] = ayas['b1'] + 2\n",
    "  ayas['m1'] = ayas['m2'] - 1\n",
    "  ayas['m3'] = ayas['m2'] + 1\n",
    "  ayas['e1'] = ayas['e3'] - 2\n",
    "  ayas['e2'] = ayas['e3'] - 1\n",
    "  for aName in 'b1 e3 b2 e2 b3 e1 m1 m3 m2'.split():\n",
    "    a = ayas[aName]\n",
    "    pos = 1 if aName.startswith('b') else -1 if aName.startswith('e') else 0\n",
    "    for w in L.d(a, otype='word'):\n",
    "      if F.pos.v(w) in contentCats:\n",
    "        positivity[F.lemma.v(w)] += pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of lemmas and their positivity\n",
    "\n",
    "We show the positivity of the lemmas of this sura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (lemma, pos) in sorted(\n",
    "  positivity.items(),\n",
    "  key=lambda x: (-x[1], x[0]),\n",
    "):\n",
    "  print(f'{lemma:<20} has positivity {pos:>2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coloring the sura\n",
    "\n",
    "Finally, we display the whole sura with words colored according to their positivity or negativity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color gradients\n",
    "\n",
    "Negative words marked red, and postive ones marked green.\n",
    "The farther from zero, the darker the color.\n",
    "\n",
    "The \n",
    "[HSL scheme](https://developer.mozilla.org/en-US/docs/Web/CSS/color_value#HSL_colors)\n",
    "of color specification is very convenient here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posColor(p):\n",
    "  if p <= -20:\n",
    "    return 'hsl(0, 100%, 50%)'\n",
    "  if p <= -5:\n",
    "    return 'hsl(0, 90%, 60%)'\n",
    "  if p <= -3:\n",
    "    return 'hsl(0, 80%, 70%)'\n",
    "  if p == -2:\n",
    "    return 'hsl(30, 80%, 70%)'\n",
    "  if p == -1:\n",
    "    return 'hsl(60, 80%, 70%)'\n",
    "  if p == 0:\n",
    "    return 'hsl(90, 70%, 80%)'\n",
    "  if p == 1:\n",
    "    return 'hsl(120, 80%, 70%)'\n",
    "  if p == 2:\n",
    "    return 'hsl(120, 90%, 80%)'\n",
    "  if p == 3:\n",
    "    return 'hsl(120, 100%, 90%)'\n",
    "  if p == 4:\n",
    "    return 'hsl(120, 100%, 100%)'\n",
    "  if p >= 4:\n",
    "    return 'hsl(150, 100%, 100%)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing highlights\n",
    "\n",
    "We just compute a highlight mapping, much like we did before, but now we are going to highlight\n",
    "all words in the sura that have a positivity or negativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startAyaNodes = set()\n",
    "endAyaNodes = set()\n",
    "\n",
    "for (beginAnum, endAnum) in sections:\n",
    "  beginA = T.nodeFromSection((2, beginAnum))\n",
    "  endA = T.nodeFromSection((2, endAnum))\n",
    "  startAyaNodes.add(beginA)\n",
    "  endAyaNodes.add(endA)\n",
    "highlights = {}\n",
    "\n",
    "for a in sura2Ayas:\n",
    "  words = L.d(a, otype='word')\n",
    "  firstWord = words[0]\n",
    "  isVoc = F.posx.v(firstWord) == 'vocative'\n",
    "  isRes = F.posx.v(firstWord) == 'resumption'\n",
    "  for w in words:\n",
    "    if w == firstWord:\n",
    "      if isVoc or isRes:\n",
    "        highlights[firstWord] = 'lime' if isVoc else 'fuchsia'\n",
    "    if F.lemma.v(w) in positivity:\n",
    "      pos = positivity[F.lemma.v(w)]\n",
    "      highlights[w] = posColor(pos)\n",
    "  if a in startAyaNodes:\n",
    "    highlights[a] = 'gold'\n",
    "  elif a in endAyaNodes:\n",
    "    highlights[a] = 'lightcoral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colored sentiment display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.table(ayaTuples, highlights=highlights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Saving data\n",
    "\n",
    "The real power of TF comes now: we can save the sentiments as a new feature and use it as if it were given with the data set.\n",
    "\n",
    "We save it to a temporary location, in your downloads folder, and load it from there.\n",
    "\n",
    "We use\n",
    "[TF.save()](https://annotation.github.io/text-fabric/Api/Fabric/#saving-features) to save the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering the parameters\n",
    "\n",
    "We set up all data that `TF.save()` needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData = {\n",
    "  'sentiment': {\n",
    "    'valueType': 'int',\n",
    "    'description': 'crude sentiment values for some words in sura 2',\n",
    "  },\n",
    "}\n",
    "\n",
    "edgeFeatures = {}\n",
    "nodeFeatures = {\n",
    "  'sentiment': {w: positivity[F.lemma.v(w)] for w in L.d(sura2, otype='word') if F.lemma.v(w) in positivity},\n",
    "}\n",
    "\n",
    "location = os.path.expanduser('~/Downloads/q-ran/quran/tf')\n",
    "module = A.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the save\n",
    "\n",
    "Now we do the save action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.save(metaData=metaData, edgeFeatures=edgeFeatures, nodeFeatures=nodeFeatures, location=location, module=module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking\n",
    "\n",
    "Let's check (maybe this does not work on Windows. Open the file explorer and locate the file yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "ls -lR ~/Downloads/q-ran/quran/tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Using new data\n",
    "\n",
    "We are going to load the Quran data again plus the sentiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the sentiment data\n",
    "\n",
    "We use roughly the same statement as when we first loaded the data,\n",
    "but now we ask TF also to look into the directory where we saved the sentiments.\n",
    "\n",
    "We do that by supplying the `locations` and `modules` parameters.\n",
    "\n",
    "See also\n",
    "[A.use()](https://annotation.github.io/text-fabric/Api/App/#incantation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = use('quran', hoist=globals(), locations=location, modules=module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See: the feature `sentiment` got loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the sentiment data\n",
    "\n",
    "Let's inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.sentiment.freqList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, a bit more pleasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (sent, amount) in F.sentiment.freqList():\n",
    "  print(f'sentiment {sent:>3} occurs {amount:>3} times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying sentiment data\n",
    "\n",
    "Remember the display where we showed the morphology and the translations?\n",
    "\n",
    "We can make the same display, but now with sentiments shown.\n",
    "\n",
    "We show only some of the ayas.\n",
    "\n",
    "We have to add the feature `sentiment` to the features to be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.displaySetup(extraFeatures='translation@en sentiment')\n",
    "A.show(ayaTuples, start=10, end=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for sentiment data\n",
    "\n",
    "We can use the sentiment feature in searches.\n",
    "\n",
    "Let's look for negative words in ayas starting with a vocative particle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "sura number=2\n",
    "  aya\n",
    "    =: word posx=vocative\n",
    "    word sentiment<0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = A.search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we show the results, lets furnish an uncluttered\n",
    "[display](https://annotation.github.io/text-fabric/Api/App/#display)\n",
    "by suppressing a number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.displaySetup(extraFeatures='translation@en sentiment', suppress='number case gn nu formation tense root')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see multiple negative words of an aya highlighted in the same aya, instead of displaying the aya over and over again for each\n",
    "negative word. Hence we'll pass `condensed=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.show(results, condensed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to Excel\n",
    "\n",
    "It is convenient to export this to Excel, for more intense inspection, aided by all the tools that Excel has to offer for sorting, filtering and making charts.\n",
    "\n",
    "We use the function \n",
    "[A.export()]()\n",
    "to do this.\n",
    "\n",
    "This function takes a list of node tuples, retrieves data about those nodes, and writes it to a .tsv file (tab-separated), that\n",
    "can be opened by Excel (even with Arabic characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.export(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is now in your Downloads folder, with name `results.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "ls -l ~/Downloads/results.tsv\n",
    "head -n 10 ~/Downloads/results.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very pretty, because the file is in utf16 and the terminal does not handle that well.\n",
    "But this is the encoding that Excel can use, and there it looks allright:\n",
    "\n",
    "![nega](images/negativeExcel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Share your data\n",
    "\n",
    "You can share the new `sentiment` feature in such a way that others can use it easily, even more easy than we just did.\n",
    "\n",
    "The thing to do is:\n",
    "\n",
    "* use text-fabric to store your features in a zip file\n",
    "* make or use a github repository\n",
    "* create a new release and add the zip file to it\n",
    "\n",
    "These steps are explained in the [share](share.ipynb) tutorial.\n",
    "There we made an even cruder feature `sentiment`, with words in all suras, and stored it on GitHub\n",
    "in\n",
    "[q-ran/exercises/mining/tf](https://github.com/q-ran/exercises/tree/master/mining/tf/0.3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Re-use your data\n",
    "\n",
    "That means that we can call up that data alongside the Quran data by passing an extra argument to `use()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = use('quran', hoist=globals(), mod='q-ran/exercises/mining/tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can now click on the `sentiment` feature above, which will bring you to\n",
    "the repository where it is stored.\n",
    "If the creator of the data did a good job, you'll find documentation about `sentiment` in its readme file\n",
    "or docs directory.\n",
    "\n",
    "We check the feature itself for its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.sentiment.freqList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can load as many extra modules as you want. If one researcher adds semantic domains, another sentiments, yet another named\n",
    "entities, then everybody can use semantics, sentiments and entities in one go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "All chapters:\n",
    "\n",
    "* **[start](start.ipynb)** introduction to computing with your corpus\n",
    "* **[display](display.ipynb)** become an expert in creating pretty displays of your text structures\n",
    "* **[search](search.ipynb)** turbo charge your hand-coding with search templates\n",
    "* **[exportExcel](exportExcel.ipynb)** make tailor-made spreadsheets out of your results\n",
    "* **[share](share.ipynb)** draw in other people's data and let them use yours\n",
    "* **[similarAyas](similarAyas.ipynb)** spot the similarities between lines\n",
    "* **rings** ring structures in sura 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
