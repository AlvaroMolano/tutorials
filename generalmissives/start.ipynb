{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"images/logo.png\" width=\"300\"/>\n",
    "<img align=\"right\" src=\"images/tf.png\" width=\"128\"/>\n",
    "<img align=\"right\" src=\"images/huygenslogo.png\" width=\"128\"/>\n",
    "<img align=\"right\" src=\"images/dans.png\" width=\"128\"/>\n",
    "\n",
    "# Tutorial\n",
    "\n",
    "This notebook gets you started with using\n",
    "[Text-Fabric](https://annotation.github.io/text-fabric/) for coding in the\n",
    "[General Missives corpus](https://github.com/Dans-labs/clariah-gm)\n",
    "(1600-1800).\n",
    "\n",
    "Familiarity with the underlying\n",
    "[data model](https://annotation.github.io/text-fabric/about/datamodel.html)\n",
    "is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Text-Fabric\n",
    "\n",
    "### Python\n",
    "\n",
    "You need to have Python on your system. Most systems have it out of the box,\n",
    "but alas, that is python2 and we need at least python **3.6**.\n",
    "\n",
    "Install it from [python.org](https://www.python.org) or from\n",
    "[Anaconda](https://www.anaconda.com/download).\n",
    "\n",
    "### TF itself\n",
    "\n",
    "```\n",
    "pip3 install text-fabric\n",
    "```\n",
    "\n",
    "### Jupyter notebook\n",
    "\n",
    "You need [Jupyter](http://jupyter.org).\n",
    "\n",
    "If it is not already installed:\n",
    "\n",
    "```\n",
    "pip3 install jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip\n",
    "If you cloned the repository containing this tutorial,\n",
    "first copy its parent directory to somewhere outside your clone of the repo,\n",
    "before computing with this it.\n",
    "\n",
    "If you pull changes from the repository later, it will not conflict with\n",
    "your computations.\n",
    "\n",
    "Where you put your tutorial directory is up to you.\n",
    "It will work from any directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus data\n",
    "\n",
    "Text-Fabric will fetch the data set for you from the newest github release binaries.\n",
    "\n",
    "The data will be stored in the `text-fabric-data` in your home directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "The data of the corpus is organized in features.\n",
    "They are *columns* of data.\n",
    "Think of the corpus as a gigantic spreadsheet, where row 1 corresponds to the\n",
    "first sign, row 2 to the second sign, and so on, for all ??? words.\n",
    "\n",
    "The information which reading each sign has, constitutes a column in that spreadsheet.\n",
    "The General Missives corpus contains ?? columns, not only for the words, but also for thousands of other\n",
    "textual objects, such as pages, divs, paragraphs, lines, notes, documents.\n",
    "\n",
    "Instead of putting that information in one big table, the data is organized in separate columns.\n",
    "We call those columns **features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:16.202764Z",
     "start_time": "2018-05-18T09:17:16.197546Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incantation\n",
    "\n",
    "The simplest way to get going is by this *incantation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:17.537171Z",
     "start_time": "2018-05-18T09:17:17.517809Z"
    }
   },
   "outputs": [],
   "source": [
    "from tf.app import use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the very last version, use `hot`.\n",
    "\n",
    "For the latest release, use `latest`.\n",
    "\n",
    "If you have cloned the repos (TF app and data), use `clone`.\n",
    "\n",
    "If you do not want/need to upgrade, leave out the checkout specifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = use('generalmissives:clone', checkout=\"clone\", hoist=globals())\n",
    "# A = use('generalmissives:hot', checkout=\"hot\", hoist=globals())\n",
    "# A = use('generalmissives:latest', checkout=\"latest\", hoist=globals())\n",
    "# A = use('generalmissives', hoist=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see which features have been loaded, and if you click on a feature name, you find its documentation.\n",
    "If you hover over a name, you see where the feature is located on your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API\n",
    "\n",
    "The result of the incantation is that we have a bunch of special variables at our disposal\n",
    "that give us access to the text and data of the corpus.\n",
    "\n",
    "At this point it is helpful to throw a quick glance at the text-fabric API documentation\n",
    "(see the links under **API Members** above).\n",
    "\n",
    "The most essential thing for now is that we can use `F` to access the data in the features\n",
    "we've loaded.\n",
    "But there is more, such as `N`, which helps us to walk over the text, as we see in a minute.\n",
    "\n",
    "The **API members** above show you exactly which new names have been inserted in your namespace.\n",
    "If you click on these names, you go to the API documentation for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "Text-Fabric contains a flexible search engine, that does not only work for the data,\n",
    "of this corpus, but also for other corpora and data that you add to corpora.\n",
    "\n",
    "**Search is the quickest way to come up-to-speed with your data, without too much programming.**\n",
    "\n",
    "Jump to the dedicated [search](search.ipynb) search tutorial first, to whet your appetite.\n",
    "\n",
    "The real power of search lies in the fact that it is integrated in a programming environment.\n",
    "You can use programming to:\n",
    "\n",
    "* compose dynamic queries\n",
    "* process query results\n",
    "\n",
    "Therefore, the rest of this tutorial is still important when you want to tap that power.\n",
    "If you continue here, you learn all the basics of data-navigation with Text-Fabric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting\n",
    "\n",
    "In order to get acquainted with the data, we start with the simple task of counting.\n",
    "\n",
    "## Count all nodes\n",
    "We use the \n",
    "[`N()` generator](https://annotation.github.io/text-fabric/Api/General/#navigating-nodes)\n",
    "to walk through the nodes.\n",
    "\n",
    "We compared the TF data to a gigantic spreadsheet, where the rows correspond to the signs.\n",
    "In Text-Fabric, we call the rows `slots`, because they are the textual positions that can be filled with signs.\n",
    "\n",
    "We also mentioned that there are also other textual objects. \n",
    "They are the clusters, lines, faces and documents.\n",
    "They also correspond to rows in the big spreadsheet.\n",
    "\n",
    "In Text-Fabric we call all these rows *nodes*, and the `N()` generator\n",
    "carries us through those nodes in the textual order.\n",
    "\n",
    "Just one extra thing: the `info` statements generate timed messages.\n",
    "If you use them instead of `print` you'll get a sense of the amount of time that \n",
    "the various processing steps typically need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:43.894153Z",
     "start_time": "2018-05-18T09:17:43.597128Z"
    }
   },
   "outputs": [],
   "source": [
    "A.indent(reset=True)\n",
    "A.info('Counting nodes ...')\n",
    "\n",
    "i = 0\n",
    "for n in N.walk(): i += 1\n",
    "\n",
    "A.info('{} nodes'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see it: well over a million nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are those nodes?\n",
    "Every node has a type, like sign, or line, face.\n",
    "But what exactly are they?\n",
    "\n",
    "Text-Fabric has two special features, `otype` and `oslots`, that must occur in every Text-Fabric data set.\n",
    "`otype` tells you for each node its type, and you can ask for the number of `slot`s in the text.\n",
    "\n",
    "Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:47.820323Z",
     "start_time": "2018-05-18T09:17:47.812328Z"
    }
   },
   "outputs": [],
   "source": [
    "F.otype.slotType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:48.549430Z",
     "start_time": "2018-05-18T09:17:48.543371Z"
    }
   },
   "outputs": [],
   "source": [
    "F.otype.maxSlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:49.251302Z",
     "start_time": "2018-05-18T09:17:49.244467Z"
    }
   },
   "outputs": [],
   "source": [
    "F.otype.maxNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:49.922863Z",
     "start_time": "2018-05-18T09:17:49.916078Z"
    }
   },
   "outputs": [],
   "source": [
    "F.otype.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:51.782779Z",
     "start_time": "2018-05-18T09:17:51.774167Z"
    }
   },
   "outputs": [],
   "source": [
    "C.levels.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting: above you see all the textual objects, with the average size of their objects,\n",
    "the node where they start, and the node where they end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count individual object types\n",
    "This is an intuitive, but inefficient way to count the number of nodes in each type.\n",
    "Note in passing, how we use the `indent` in conjunction with `info` to produce neat timed \n",
    "and indented progress messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:57.806821Z",
     "start_time": "2018-05-18T09:17:57.558523Z"
    }
   },
   "outputs": [],
   "source": [
    "A.indent(reset=True)\n",
    "A.info('counting objects ...')\n",
    "\n",
    "for otype in F.otype.all:\n",
    "    i = 0\n",
    "\n",
    "    A.indent(level=1, reset=True)\n",
    "\n",
    "    for n in F.otype.s(otype): i+=1\n",
    "\n",
    "    A.info('{:>7} {}s'.format(i, otype))\n",
    "\n",
    "A.indent(level=0)\n",
    "A.info('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much more efficient is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:57.806821Z",
     "start_time": "2018-05-18T09:17:57.558523Z"
    }
   },
   "outputs": [],
   "source": [
    "A.indent(reset=True)\n",
    "A.info('counting objects ...')\n",
    "\n",
    "for otype in F.otype.all:\n",
    "    i = 0\n",
    "\n",
    "    A.indent(level=1, reset=True)\n",
    "    amount = len(F.otype.s(otype))\n",
    "    A.info(f'{amount:>7} {otype}s')\n",
    "\n",
    "A.indent(level=0)\n",
    "A.info('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But nothing beats this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lv in C.levels.data:\n",
    "    print(f\"{lv[3] - lv[2] + 1:>6} {lv[0]}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing textual objects\n",
    "\n",
    "You can use the A API (the extra power) to display cuneiform text.\n",
    "\n",
    "See the [display](display.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature statistics\n",
    "\n",
    "`F`\n",
    "gives access to all features.\n",
    "Every feature has a method\n",
    "`freqList()`\n",
    "to generate a frequency list of its values, higher frequencies first.\n",
    "Here are the repeats of numerals (the `-1` comes from a `n(rrr)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:18.039544Z",
     "start_time": "2018-05-18T09:18:17.784073Z"
    }
   },
   "outputs": [],
   "source": [
    "F.repeat.freqList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signs have types and clusters have types. We can count them separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:18.039544Z",
     "start_time": "2018-05-18T09:18:17.784073Z"
    }
   },
   "outputs": [],
   "source": [
    "F.type.freqList('cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:18.039544Z",
     "start_time": "2018-05-18T09:18:17.784073Z"
    }
   },
   "outputs": [],
   "source": [
    "F.type.freqList('sign')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in passing that we have nearly 15,000 word dividers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:18.039544Z",
     "start_time": "2018-05-18T09:18:17.784073Z"
    }
   },
   "outputs": [],
   "source": [
    "F.flags.freqList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word matters\n",
    "\n",
    "## Top 20 frequent words\n",
    "\n",
    "We represent words by their essential symbols, collected in the feature *sym* (which also exists for signs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (w, amount) in F.sym.freqList('word')[0:20]:\n",
    "  print(f'{amount:>5} {w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word distribution\n",
    "\n",
    "Let's do a bit more fancy word stuff.\n",
    "\n",
    "### Hapaxes\n",
    "\n",
    "A hapax can be found by picking the words with frequency 1\n",
    "\n",
    "We print 20 hapaxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in [w for (w, amount) in F.sym.freqList('word') if amount == 1][0:20]:\n",
    "  print(f'\"{w}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small occurrence base\n",
    "\n",
    "The occurrence base of a word are the documents in which occurs.\n",
    "\n",
    "We compute the occurrence base of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrenceBase = collections.defaultdict(set)\n",
    "\n",
    "for w in F.otype.s('word'):\n",
    "  pNum = T.sectionFromNode(w)[0]\n",
    "  occurrenceBase[F.sym.v(w)].add(pNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of how many words have how big occurrence bases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrenceSize = collections.Counter()\n",
    "\n",
    "for (w, pNums) in occurrenceBase.items():\n",
    "  occurrenceSize[len(pNums)] += 1\n",
    "  \n",
    "occurrenceSize = sorted(\n",
    "  occurrenceSize.items(),\n",
    "  key=lambda x: (-x[1], x[0]),\n",
    ")\n",
    "\n",
    "for (size, amount) in occurrenceSize[0:10]:\n",
    "  print(f'base size {size:>4} : {amount:>5} words')\n",
    "print('...')\n",
    "for (size, amount) in occurrenceSize[-10:]:\n",
    "  print(f'base size {size:>4} : {amount:>5} words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give the predicate *private* to those words whose occurrence base is a single document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privates = {w for (w, base) in occurrenceBase.items() if len(base) == 1}\n",
    "len(privates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peculiarity of documents\n",
    "\n",
    "As a final exercise with words, lets make a list of all documents, and show their\n",
    "\n",
    "* total number of words\n",
    "* number of private words\n",
    "* the percentage of private words: a measure of the peculiarity of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:52.143337Z",
     "start_time": "2018-05-18T09:18:52.130385Z"
    }
   },
   "outputs": [],
   "source": [
    "docList = []\n",
    "\n",
    "empty = set()\n",
    "ordinary = set()\n",
    "\n",
    "for d in F.otype.s('document'):\n",
    "  pNum = T.documentName(d)\n",
    "  words = {F.sym.v(w) for w in L.d(d, otype='word')}\n",
    "  a = len(words)\n",
    "  if not a:\n",
    "    empty.add(pNum)\n",
    "    continue\n",
    "  o = len({w for w in words if w in privates})\n",
    "  if not o:\n",
    "    ordinary.add(pNum)\n",
    "    continue\n",
    "  p = 100 * o / a\n",
    "  docList.append((pNum, a, o, p))\n",
    "\n",
    "docList = sorted(docList, key=lambda e: (-e[3], -e[1], e[0]))\n",
    "\n",
    "print(f'Found {len(empty):>4} empty documents')\n",
    "print(f'Found {len(ordinary):>4} ordinary documents (i.e. without private words)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:52.143337Z",
     "start_time": "2018-05-18T09:18:52.130385Z"
    }
   },
   "outputs": [],
   "source": [
    "print('{:<20}{:>5}{:>5}{:>5}\\n{}'.format(\n",
    "    'document', '#all', '#own', '%own',\n",
    "    '-'*35,\n",
    "))\n",
    "\n",
    "for x in docList[0:20]:\n",
    "  print('{:<20} {:>4} {:>4} {:>4.1f}%'.format(*x))\n",
    "print('...')\n",
    "for x in docList[-20:]:\n",
    "  print('{:<20} {:>4} {:>4} {:>4.1f}%'.format(*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locality API\n",
    "We travel upwards and downwards, forwards and backwards through the nodes.\n",
    "The Locality-API (`L`) provides functions: `u()` for going up, and `d()` for going down,\n",
    "`n()` for going to next nodes and `p()` for going to previous nodes.\n",
    "\n",
    "These directions are indirect notions: nodes are just numbers, but by means of the\n",
    "`oslots` feature they are linked to slots. One node *contains* an other node, if the one is linked to a set of slots that contains the set of slots that the other is linked to.\n",
    "And one if next or previous to an other, if its slots follow or precede the slots of the other one.\n",
    "\n",
    "`L.u(node)` **Up** is going to nodes that embed `node`.\n",
    "\n",
    "`L.d(node)` **Down** is the opposite direction, to those that are contained in `node`.\n",
    "\n",
    "`L.n(node)` **Next** are the next *adjacent* nodes, i.e. nodes whose first slot comes immediately after the last slot of `node`.\n",
    "\n",
    "`L.p(node)` **Previous** are the previous *adjacent* nodes, i.e. nodes whose last slot comes immediately before the first slot of `node`.\n",
    "\n",
    "All these functions yield nodes of all possible otypes.\n",
    "By passing an optional parameter, you can restrict the results to nodes of that type.\n",
    "\n",
    "The result are ordered according to the order of things in the text.\n",
    "\n",
    "The functions return always a tuple, even if there is just one node in the result.\n",
    "\n",
    "## Going up\n",
    "We go from the first word to the document it contains.\n",
    "Note the `[0]` at the end. You expect one document, yet `L` returns a tuple. \n",
    "To get the only element of that tuple, you need to do that `[0]`.\n",
    "\n",
    "If you are like me, you keep forgetting it, and that will lead to weird error messages later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:55.410034Z",
     "start_time": "2018-05-18T09:18:55.404051Z"
    }
   },
   "outputs": [],
   "source": [
    "firstDoc = L.u(1, otype='document')[0]\n",
    "print(firstDoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's see all the containing objects of sign 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:56.772513Z",
     "start_time": "2018-05-18T09:18:56.766324Z"
    }
   },
   "outputs": [],
   "source": [
    "s = 3\n",
    "for otype in F.otype.all:\n",
    "  if otype == F.otype.slotType: continue\n",
    "  up = L.u(s, otype=otype)\n",
    "  upNode = 'x' if len(up) == 0 else up[0]\n",
    "  print('sign {} is contained in {} {}'.format(s, otype, upNode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going next\n",
    "Let's go to the next nodes of the first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:58.821681Z",
     "start_time": "2018-05-18T09:18:58.814893Z"
    }
   },
   "outputs": [],
   "source": [
    "afterFirstDoc = L.n(firstDoc)\n",
    "for n in afterFirstDoc:\n",
    "  print('{:>7}: {:<13} first slot={:<6}, last slot={:<6}'.format(\n",
    "      n, F.otype.v(n),\n",
    "      E.oslots.s(n)[0],\n",
    "      E.oslots.s(n)[-1],\n",
    "  ))\n",
    "secondDoc = L.n(firstDoc, otype='document')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going previous\n",
    "\n",
    "And let's see what is right before the second document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:00.163973Z",
     "start_time": "2018-05-18T09:19:00.154857Z"
    }
   },
   "outputs": [],
   "source": [
    "for n in L.p(secondDoc):\n",
    "  print('{:>7}: {:<13} first slot={:<6}, last slot={:<6}'.format(\n",
    "      n, F.otype.v(n),\n",
    "      E.oslots.s(n)[0],\n",
    "      E.oslots.s(n)[-1],\n",
    "  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go to the faces of the first document, and just count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:02.530705Z",
     "start_time": "2018-05-18T09:19:02.475279Z"
    }
   },
   "outputs": [],
   "source": [
    "faces = L.d(firstDoc, otype='face')\n",
    "print(len(faces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first line\n",
    "We pick two nodes and explore what is above and below them:\n",
    "the first line and the first word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:04.024679Z",
     "start_time": "2018-05-18T09:19:03.995207Z"
    }
   },
   "outputs": [],
   "source": [
    "for n in [\n",
    "    F.otype.s('word')[0],\n",
    "    F.otype.s('line')[0],\n",
    "]:\n",
    "  A.indent(level=0)\n",
    "  A.info('Node {}'.format(n), tm=False)\n",
    "  A.indent(level=1)\n",
    "  A.info('UP', tm=False)\n",
    "  A.indent(level=2)\n",
    "  A.info('\\n'.join(['{:<15} {}'.format(u, F.otype.v(u)) for u in L.u(n)]), tm=False)\n",
    "  A.indent(level=1)\n",
    "  A.info('DOWN', tm=False)\n",
    "  A.indent(level=2)\n",
    "  A.info('\\n'.join(['{:<15} {}'.format(u, F.otype.v(u)) for u in L.d(n)]), tm=False)\n",
    "A.indent(level=0)\n",
    "A.info('Done', tm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text API\n",
    "\n",
    "So far, we have mainly seen nodes and their numbers, and the names of node types.\n",
    "You would almost forget that we are dealing with text.\n",
    "So let's try to see some text.\n",
    "\n",
    "In the same way as `F` gives access to feature data,\n",
    "`T` gives access to the text.\n",
    "That is also feature data, but you can tell Text-Fabric which features are specifically\n",
    "carrying the text, and in return Text-Fabric offers you\n",
    "a Text API: `T`.\n",
    "\n",
    "## Formats\n",
    "Cuneiform text can be represented in a number of ways:\n",
    "\n",
    "* original ATF, with bracketings and flags\n",
    "* essential symbols: readings and graphemes, repeats and fractions (of numerals), no flags, no clusterings\n",
    "* unicode symbols\n",
    "\n",
    "If you wonder where the information about text formats is stored: \n",
    "not in the program text-fabric, but in the data set.\n",
    "It has a feature `otext`, which specifies the formats and which features\n",
    "must be used to produce them. `otext` is the third special feature in a TF data set,\n",
    "next to `otype` and `oslots`. \n",
    "It is an optional feature. \n",
    "If it is absent, there will be no `T` API.\n",
    "\n",
    "Here is a list of all available formats in this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:05.606582Z",
     "start_time": "2018-05-18T09:19:05.593486Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted(T.formats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the formats\n",
    "\n",
    "The ` T.text()` function is central to get text representations of nodes. Its most basic usage is\n",
    "\n",
    "```python\n",
    "T.text(nodes, fmt=fmt)\n",
    "```\n",
    "where `nodes` is a list or iterable of nodes, usually word nodes, and `fmt` is the name of a format.\n",
    "If you leave out `fmt`, the default `text-orig-full` is chosen.\n",
    "\n",
    "The result is the text in that format for all nodes specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text([1,2,3,4,5,6,7,8,9,10,11], fmt='text-orig-plain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also another usage of this function:\n",
    "\n",
    "```python\n",
    "T.text(node, fmt=fmt)\n",
    "```\n",
    "\n",
    "where `node` is a single node.\n",
    "In this case, the default format is *ntype*`-orig-full` where *ntype* is the type of `node`.\n",
    "\n",
    "If the format is defined in the corpus, it will be used. Otherwise, the word nodes contained in `node` will be looked up\n",
    "and represented with the default format `text-orig-full`.\n",
    "\n",
    "In this way we can sensibly represent a lot of different nodes, such as documents, faces, lines, clusters, words and signs.\n",
    "\n",
    "We compose a set of example nodes and run `T.text` on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleNodes = [\n",
    "  F.otype.s('sign')[0],\n",
    "  F.otype.s('word')[0],\n",
    "  F.otype.s('cluster')[0],\n",
    "  F.otype.s('line')[0],\n",
    "  F.otype.s('face')[0],\n",
    "  F.otype.s('document')[0],\n",
    "]\n",
    "exampleNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in exampleNodes:\n",
    "  print(f'This is {F.otype.v(n)} {n}:')\n",
    "  print(T.text(n))\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the formats\n",
    "Now let's use those formats to print out the first line in this corpus.\n",
    "\n",
    "Note that only the formats starting with `text-` are usable for this.\n",
    "\n",
    "For the `layout-` formats, see [display](display.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:10.077589Z",
     "start_time": "2018-05-18T09:19:10.070503Z"
    }
   },
   "outputs": [],
   "source": [
    "for fmt in sorted(T.formats):\n",
    "  if fmt.startswith('text-'):\n",
    "    print('{}:\\n\\t{}'.format(fmt, T.text(range(1,12), fmt=fmt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not specify a format, the **default** format is used (`text-orig-full`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:13.490426Z",
     "start_time": "2018-05-18T09:19:13.486053Z"
    }
   },
   "outputs": [],
   "source": [
    "T.text(range(1,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstLine = F.otype.s('line')[0]\n",
    "T.text(firstLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(firstLine, fmt='text-orig-unicode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word dividers\n",
    "\n",
    "First we grab all word dividers in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = F.type.s('wdiv')\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we take the first word divider and look up the line in which it occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ds[0]\n",
    "l = L.u(d, otype=\"line\")[0]\n",
    "A.webLink(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ATF source of this line is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.getSource(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the text formats to display this line in various forms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(l, fmt=\"text-orig-plain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(l, fmt=\"text-orig-rich\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.text(l, fmt=\"text-orig-unicode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These characters do not look right, but that is because of the font. We can show the text in the right font with the more advanced functions of Text-Fabric (see also [display](display.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.plain(l, fmt=\"text-orig-unicode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now with the word divider higlighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.plain(l, fmt=\"text-orig-unicode\", highlights=set(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important things to remember are:\n",
    "\n",
    "* you can supply a list of slot nodes and get them represented in all formats\n",
    "* you can get non-slot nodes `n` in default format by `T.text(n)`\n",
    "* you can get non-slot nodes `n` in other formats by `T.text(n, fmt=fmt, descend=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole text in all formats in just 6 seconds\n",
    "Part of the pleasure of working with computers is that they can crunch massive amounts of data.\n",
    "The text of the Old Assyrian Letters is a piece of cake.\n",
    "\n",
    "It takes just ten seconds to have that cake and eat it. \n",
    "In nearly a dozen formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:27.839331Z",
     "start_time": "2018-05-18T09:19:18.526400Z"
    }
   },
   "outputs": [],
   "source": [
    "A.indent(reset=True)\n",
    "A.info('writing plain text of all letters in all text formats')\n",
    "\n",
    "text = collections.defaultdict(list)\n",
    "\n",
    "for l in F.otype.s('line'):\n",
    "  for fmt in sorted(T.formats):\n",
    "    if fmt.startswith('text-'):\n",
    "      text[fmt].append(T.text(l, fmt=fmt, descend=True))\n",
    "\n",
    "A.info('done {} formats'.format(len(text)))\n",
    "\n",
    "for fmt in sorted(text):\n",
    "    print('{}\\n{}\\n'.format(fmt, '\\n'.join(text[fmt][0:5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The full plain text\n",
    "We write all formats to file, in your `Downloads` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:34.250294Z",
     "start_time": "2018-05-18T09:19:34.156658Z"
    }
   },
   "outputs": [],
   "source": [
    "for fmt in T.formats:\n",
    "  if fmt.startswith('text-'):\n",
    "    with open(os.path.expanduser(f'~/Downloads/{fmt}.txt'), 'w') as f:\n",
    "      f.write('\\n'.join(text[fmt]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections\n",
    "\n",
    "A section in the letter corpus is a document, a face or a line.\n",
    "Knowledge of sections is not baked into Text-Fabric. \n",
    "The config feature `otext.tf` may specify three section levels, and tell\n",
    "what the corresponding node types and features are.\n",
    "\n",
    "From that knowledge it can construct mappings from nodes to sections, e.g. from line\n",
    "nodes to tuples of the form:\n",
    "\n",
    "    (p-number, face specifier, line number)\n",
    "    \n",
    "You can get the section of a node as a tuple of relevant document, face, and line nodes.\n",
    "Or you can get it as a passage label, a string.\n",
    "\n",
    "You can ask for the passage corresponding to the first slot of a node, or the one corresponding to the last slot.\n",
    "\n",
    "If you are dealing with document and face nodes, you can ask to fill out the line and face parts as well.\n",
    "   \n",
    "Here are examples of getting the section that corresponds to a node and vice versa.\n",
    "\n",
    "**NB:** `sectionFromNode` always delivers a verse specification, either from the\n",
    "first slot belonging to that node, or, if `lastSlot`, from the last slot\n",
    "belonging to that node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someNodes = (\n",
    "  F.otype.s('sign')[100000],\n",
    "  F.otype.s('word')[10000],\n",
    "  F.otype.s('cluster')[5000],\n",
    "  F.otype.s('line')[15000],\n",
    "  F.otype.s('face')[1000],\n",
    "  F.otype.s('document')[500],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:43.056511Z",
     "start_time": "2018-05-18T09:19:43.043552Z"
    }
   },
   "outputs": [],
   "source": [
    "for n in someNodes:\n",
    "  nType = F.otype.v(n)\n",
    "  d = f'{n:>7} {nType}'\n",
    "  first = A.sectionStrFromNode(n)\n",
    "  last = A.sectionStrFromNode(n, lastSlot=True, fillup=True)\n",
    "  tup = (\n",
    "      T.sectionTuple(n),\n",
    "      T.sectionTuple(n, lastSlot=True, fillup=True),\n",
    "  )\n",
    "  print(f'{d:<16} - {first:<18} {last:<18} {tup}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean caches\n",
    "\n",
    "Text-Fabric pre-computes data for you, so that it can be loaded faster.\n",
    "If the original data is updated, Text-Fabric detects it, and will recompute that data.\n",
    "\n",
    "But there are cases, when the algorithms of Text-Fabric have changed, without any changes in the data, that you might\n",
    "want to clear the cache of precomputed results.\n",
    "\n",
    "There are two ways to do that:\n",
    "\n",
    "* Locate the `.tf` directory of your dataset, and remove all `.tfx` files in it.\n",
    "  This might be a bit awkward to do, because the `.tf` directory is hidden on Unix-like systems.\n",
    "* Call `TF.clearCache()`, which does exactly the same.\n",
    "\n",
    "It is not handy to execute the following cell all the time, that's why I have commented it out.\n",
    "So if you really want to clear the cache, remove the comment sign below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "By now you have an impression how to compute around in the corpus.\n",
    "While this is still the beginning, I hope you already sense the power of unlimited programmatic access\n",
    "to all the bits and bytes in the data set.\n",
    "\n",
    "Here are a few directions for unleashing that power.\n",
    "\n",
    "* **[display](display.ipynb)** become an expert in creating pretty displays of your text structures\n",
    "* **[search](search.ipynb)** turbo charge your hand-coding with search templates\n",
    "* **[exportExcel](exportExcel.ipynb)** make tailor-made spreadsheets out of your results\n",
    "* **[share](share.ipynb)** draw in other people's data and let them use yours\n",
    "* **[similarLines](similarLines.ipynb)** spot the similarities between lines\n",
    "\n",
    "---\n",
    "\n",
    "See the [cookbook](cookbook) for recipes for small, concrete tasks.\n",
    "\n",
    "CC-BY Dirk Roorda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
