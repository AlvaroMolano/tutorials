{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/tf.png\" width=\"128\"/>\n",
    "<img align=\"right\" src=\"images/ninologo.png\" width=\"128\"/>\n",
    "<img align=\"right\" src=\"images/dans.png\" width=\"128\"/>\n",
    "\n",
    "---\n",
    "\n",
    "To get started: consult [start](start.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "# Part of Speech tagging\n",
    "\n",
    "## Team\n",
    "\n",
    "* Alba de Ridder: Assyriology, master student @ NINO, Leiden\n",
    "* Martijn Kokken: Assyriology, master student @ NINO, Leiden\n",
    "* Dirk Roorda: Computer Science, researcher @ DANS, Den Haag\n",
    "* Cale Johnson: Assyriology, researcher & lecturer @ Univ Birmingham\n",
    "* Caroline Waerzeggers: Assyriology, head @ NINO, Leiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOPHON = dict(\n",
    "  acronym='ABB-pos',\n",
    "  corpus='Old Babylonian Letter Corpus (ABB)',\n",
    "  dataset='oldbabylonian',\n",
    "  compiler='Dirk Roorda',\n",
    "  editors='Alba de Ridder, Martijn Kokken',\n",
    "  initiators='Cale Johnson, Caroline Waerzeggers',\n",
    "  institute='NINO, DANS',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status\n",
    "\n",
    "* 2019-06-05 Dirk has reorganised the messy code after the sprint into a repeatable and documented workflow.\n",
    "  The workflow covers special cases, prepositions, and nouns, not yet the extra insights of the sprint.\n",
    "* 2019-06-03/04 Martijn, Alba and Dirk do a two-day sprint to follow-up on heuristics supplied by Cale Johnson.\n",
    "  Martijn and Alba provide extra insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We collect and execute ideas to tag all word occurrences with a part-of-speech, such as `noun`, `prep`, `verb`.\n",
    "\n",
    "In the end, we intend to provide extra features to the Old Babylonian corpus, as a standard module that will be always loaded\n",
    "alongside the corpus.\n",
    "\n",
    "This notebook will produce two word-level features:\n",
    "\n",
    "* `pos`: main category of the word: `noun`, `verb`, `prep`, `pcl` (particle)\n",
    "* `subpos`: secondary category of the word: `rel` (relation), `neg` (negation)\n",
    "\n",
    "But in the meanwhile, it is work in progress, and during the work we collect candidate assignments in sets, which we save to disk.\n",
    "\n",
    "These sets correspond to `noun`, `prep`, `nonprep` words as far as we have tagged them in the current state of the workflow.\n",
    "\n",
    "The sets are all saved in a file `sets.tfx`, both next to this notebook (so that you can get it through GitHub), as in a shared\n",
    "Dropbox folder `obb`, so that the Akkadian specialists (Alba de Ridder, Martijn Kokken, Cale Johnson) have instant access to them and\n",
    "can test them in their TF-browser.\n",
    "\n",
    "See **Usage** at the end of this notebook for how you can make use of these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method\n",
    "\n",
    "## Overview\n",
    "\n",
    "We perform the following steps in that order:\n",
    "\n",
    "### Known words\n",
    "We identify a bunch of words in closed categories, that tend to interfere with noun/verb detection.\n",
    "We identification, we exclude them from all subsequent pattern detection.\n",
    "\n",
    "### Prepositions\n",
    "We detect a few prepositions, especially those that (nearly) always preceed a noun.\n",
    "\n",
    "### Nouns\n",
    "We use several markers to detect nouns:\n",
    "\n",
    "* determinatives\n",
    "* prepositions\n",
    "* Sumerian logograms\n",
    "* numerals\n",
    "\n",
    "We collect the marked occurrences and then look up the unmarked occurrences of the same words.\n",
    "In this way we extend the detection of nouns considerably.\n",
    "\n",
    "We have to deal with one big complication, though: **unkowns**.\n",
    "If we have marked word occurrences with unknown signs in it, we cannot be confident that unmarked occurrences\n",
    "of the same thing are really occurrences of the same underlying word.\n",
    "\n",
    "So, if we transfer categorizations from marked occurrences to unmarked occurrences, we only do so if\n",
    "the word in question does not have unknowns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the engines\n",
    "\n",
    "We load the Python modules we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "\n",
    "from tf.app import use\n",
    "\n",
    "from utils import PosTag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus and obtain a handle to it: `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@font-face {\n",
       "  font-family: \"Santakku\";\n",
       "  src:\n",
       "    local(\"Santakku.ttf\"),\n",
       "    url(\"https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/Santakku.woff?raw=true\");\n",
       "}\n",
       ".txtn,.txtn a:visited,.txtn a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: normal;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".txtp,.txtp a:visited,.txtp a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: normal;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".txtr,.txtr a:visited,.txtr a:link {\n",
       "    font-family: serif;\n",
       "    font-size: large;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".txtu,.txtu a:visited,.txtu a:link {\n",
       "    font-family: Santakku;\n",
       "    font-size: x-large;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0a6611;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    direction: ltr;\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 0.1em 0em;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-style: italic;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".pnum {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: #444444;\n",
       "}\n",
       ".nd {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #999999;\n",
       "}\n",
       ".meta {\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: row nowrap;\n",
       "}\n",
       ".features,.comments {\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".children {\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    border: 0;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".children.document {\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".children.face {\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".children.line {\n",
       "    align-items: stretch;\n",
       "    flex-flow: row nowrap;\n",
       "}\n",
       ".children.cluster {\n",
       "    flex-flow: row wrap;\n",
       "}\n",
       ".children.word {\n",
       "    align-items: stretch;\n",
       "    flex-flow: row nowrap;\n",
       "}\n",
       ".children.sign {\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".contnr {\n",
       "    width: fit-content;\n",
       "}\n",
       ".contnr.document,.contnr.face,\n",
       ".contnr.line,\n",
       ".contnr.cluster,\n",
       ".contnr.word,\n",
       ".contnr.sign {\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding:  0.5em 0.1em 0.1em 0.1em;\n",
       "    margin: 0.8em 0.1em 0.1em 0.1em;\n",
       "    border-radius: 0.2em;\n",
       "    border-style: solid;\n",
       "    border-width: 0.2em;\n",
       "    font-size: small;\n",
       "}\n",
       ".contnr.document,.contnr.face {\n",
       "    border-color: #bb8800;\n",
       "}\n",
       ".contnr.line {\n",
       "    border-color: #0088bb;\n",
       "}\n",
       ".contnr.cluster {\n",
       "    flex-flow: row wrap;\n",
       "    border: 0;\n",
       "}\n",
       ".contnr.word {\n",
       "    border-color: #44bbff;\n",
       "}\n",
       ".contnr.sign {\n",
       "    border-color: #bbbbbb;\n",
       "}\n",
       ".contnr.hl {\n",
       "    background-color: #ffee66;\n",
       "}\n",
       ".lbl.document,.lbl.face,\n",
       ".lbl.line,\n",
       ".lbl.cluster,\n",
       ".lbl.sign,.lbl.word {\n",
       "    margin-top: -1.2em;\n",
       "    margin-left: 1em;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 0.3em;\n",
       "    border-style: solid;\n",
       "    font-size: small;\n",
       "    display: block;\n",
       "}\n",
       ".lbl.document,.lbl.face {\n",
       "    border-color: #bb8800;\n",
       "    border-width: 0.3em;\n",
       "    border-radius: 0.3em;\n",
       "    color: #bb8800;\n",
       "}\n",
       ".lbl.line {\n",
       "    border-color: #0088bb;\n",
       "    border-width: 0.3em;\n",
       "    border-radius: 0.3em;\n",
       "    color: #0088bb;\n",
       "}\n",
       ".lbl.cluster {\n",
       "    border-color: #dddddd;\n",
       "    border-width: 0.2em;\n",
       "    border-radius: 0.2em;\n",
       "    color: #0000cc;\n",
       "}\n",
       ".lbl.word {\n",
       "    border-color: #44bbff;\n",
       "    border-width: 0.2em;\n",
       "    border-radius: 0.2em;\n",
       "    font-size: medium;\n",
       "    color: #000000;\n",
       "}\n",
       ".lbl.sign {\n",
       "    border-color: #bbbbbb;\n",
       "    border-width: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    font-size: small;\n",
       "    color: #000000;\n",
       "}\n",
       ".op {\n",
       "    padding:  0.5em 0.1em 0.1em 0.1em;\n",
       "    margin: 0.8em 0.1em 0.1em 0.1em;\n",
       "    font-family: monospace;\n",
       "    font-size: x-large;\n",
       "    font-weight: bold;\n",
       "}\n",
       ".name {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".period {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".text {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    color: #000000;\n",
       "}\n",
       ".srcln {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #000000;\n",
       "}\n",
       ".srclnnum {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".comment {\n",
       "    color: #7777dd;\n",
       "    font-family: monospace;\n",
       "    font-size: small;\n",
       "}\n",
       ".operator {\n",
       "    color: #ff77ff;\n",
       "    font-size: large;\n",
       "}\n",
       "/* LANGUAGE: superscript and subscript */\n",
       "\n",
       "/* cluster */\n",
       ".det {\n",
       "    vertical-align: super;\n",
       "}\n",
       "/* cluster */\n",
       ".langalt {\n",
       "    vertical-align: sub;\n",
       "}\n",
       "/* REDACTIONAL: line over or under  */\n",
       "\n",
       "/* flag */\n",
       ".collated {\n",
       "    font-weight: bold;\n",
       "    text-decoration: underline;\n",
       "}\n",
       "/* cluster */\n",
       ".excised {\n",
       "    color: #dd0000;\n",
       "    text-decoration: line-through;\n",
       "}\n",
       "/* cluster */\n",
       ".supplied {\n",
       "    color: #0000ff;\n",
       "    text-decoration: overline;\n",
       "}\n",
       "/* flag */\n",
       ".remarkable {\n",
       "    font-weight: bold;\n",
       "    text-decoration: overline;\n",
       "}\n",
       "\n",
       "/* UNSURE: italic*/\n",
       "\n",
       "/* cluster */\n",
       ".uncertain {\n",
       "    font-style: italic\n",
       "}\n",
       "/* flag */\n",
       ".question {\n",
       "    font-weight: bold;\n",
       "    font-style: italic\n",
       "}\n",
       "\n",
       "/* BROKEN: text-shadow */\n",
       "\n",
       "/* cluster */\n",
       ".missing {\n",
       "    color: #999999;\n",
       "    text-shadow: #bbbbbb 1px 1px;\n",
       "}\n",
       "/* flag */\n",
       ".damage {\n",
       "    font-weight: bold;\n",
       "    color: #999999;\n",
       "    text-shadow: #bbbbbb 1px 1px;\n",
       "}\n",
       ".empty {\n",
       "  color: #ff0000;\n",
       "}\n",
       "\n",
       "\n",
       "tr.tf, td.tf, th.tf {\n",
       "  text-align: left;\n",
       "}\n",
       "\n",
       "span.hldot {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder: 0.2rem solid var(--hl-rim);\n",
       "\tborder-radius: 0.4rem;\n",
       "\t/*\n",
       "\tdisplay: inline-block;\n",
       "\twidth: 0.8rem;\n",
       "\theight: 0.8rem;\n",
       "\t*/\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "\n",
       "span.hlup {\n",
       "\tborder-color: var(--hl-dark);\n",
       "\tborder-width: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 0.2rem;\n",
       "  padding: 0.2rem;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55, 100%,  60%, 0.9  );\n",
       "\t--hl-dark:          hsla( 55, 100%,  40%, 0.9  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = use('oldbabylonian:local', checkout='local', hoist=globals(), silent='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the detection machinery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT = PosTag(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collect all the words and their occurrences and sift through determinatives and numerals.\n",
    "\n",
    "We make a dictionary of words and their occurrences.\n",
    "When we compute the word form, we pick the basic info of a sign, not the full ATF-representation with flags and brackets.\n",
    "\n",
    "We also store the form without the determinatives that are present in the word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words (all)          : 15958\n",
      "Words (nondet)       : 13872\n",
      "Words (det)          :  2088\n",
      "Words (det, stripped):  1880\n",
      "Words (numeral)      :    47\n"
     ]
    }
   ],
   "source": [
    "PT.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Known words\n",
    "\n",
    "The case specification is a string, to be read as follows:\n",
    "\n",
    "each line specifies a bunch of words, separated by `+` on the left hand side of the `=`;\n",
    "the right hand side specifies the categories those words receive, separated by `,`.\n",
    "\n",
    "The first category is the `pos`, (main part-of-speech),\n",
    "the second category is the `subpos` (sub category within the main part-of-speech).\n",
    "\n",
    "We use abbreviated forms, because users of this dataset will have to type them quite often.\n",
    "\n",
    "### Categories\n",
    "\n",
    "category | subcategory | meaning\n",
    "--- | --- | ---\n",
    "`pcl` | &nbsp; | particle (unspecified)\n",
    "`pcl` | `neg` | negative particle\n",
    "`pcl` | `rel` | relative particle\n",
    "`pcl` | `conj` | conjunction\n",
    "`prn` | `dem` | demonstrative pronoun\n",
    "`adv` | `tmp` | temporal adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = '''\n",
    "  la + u2-ul + u2-la = pcl, neg\n",
    "  sza = pcl, rel\n",
    "  u3 + u2-lu + u2 = pcl, conj\n",
    "  lu = pcl\n",
    "  an-nu-um + an-ni-im + an-nu-u2 = prn, dem\n",
    "  i-na-an-na + a-nu-um-ma = adv, tmp\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    distinct words:     13\n",
      "   pos assignments:   7681\n",
      "subpos assignments:   7293\n"
     ]
    }
   ],
   "source": [
    "PT.doKnownCases(cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepositions\n",
    "\n",
    "The following prepositions are known to precede nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preps = '''\n",
    "  i-na\n",
    "  a-na\n",
    "  e-li\n",
    "  isz-tu\n",
    "  it-ti\n",
    "  ar-ki\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " distinct words:      6\n",
      "pos assignments:   5943\n",
      "  non-prep occs:  70562\n"
     ]
    }
   ],
   "source": [
    "PT.doPreps(preps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have made a set of all non-prepositions, i.e. all word occurrences not of one of these prepositions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Nouns\n",
    "\n",
    "### pass 1: Determiners\n",
    "\n",
    "We take all words that have a determinative or a phonetic complement.\n",
    "Both are signs marked in ATF by being inside `{ }`, and in TF by having `det=1`.\n",
    "From now on, we will abrreviate it: a **det** is a determinative or a phonetic complement.\n",
    "\n",
    "We collect the *markedData* for this step: all words that have a *det* inside.\n",
    "\n",
    "The *unmarkedData* for this step are the occurrences of the stripped forms of the marked words, i.e.\n",
    "the forms with the *det*s removed.\n",
    "But only if those forms do not have `x`, `n`, `...` in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pass 2: Prepositions\n",
    "\n",
    "Words after the given set of prepositions are usually nouns.\n",
    "However, sometimes there are multiple prepositions in a row.\n",
    "We take care that we do not mark those second prepostions as nouns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pass 3: Sumerian logograms\n",
    "\n",
    "Any word that has one or more Sumerian logograms in it, will be marked as noun.\n",
    "\n",
    "Sumerian logograms are defined as signs within the scope of an enclosing `_ _` pair.\n",
    "\n",
    "In TF such signs are characterized by having `langalt=1`.\n",
    "\n",
    "The unmarked data are the occurrences of the same words, but where none of the signs have `langalt=1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pass 4: Numerals\n",
    "\n",
    "Numerals are individual signs, but they can be part of words.\n",
    "In those cases, we call the whole word a numeral.\n",
    "\n",
    "We consider the category of numeral words as a subcategory of the nouns.\n",
    "\n",
    "Note that there are also unknown numerals: those with reading `n`.\n",
    "\n",
    "A numeral is always marked, there is no concept of unmarked occurrences of numerals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before step det                    :     0 words in      0 occurrences\n",
      "Due to step det marked             :  2088 words in   6173 occurrences\n",
      "Due to step det unmarked           :   290 words in   1920 occurrences\n",
      "Due to step det all                :  2378 words in   8093 occurrences\n",
      "After  step det                    :  2378 words in   8093 occurrences\n",
      "----------------------------------------\n",
      "Before step prep                   :  2378 words in   8093 occurrences\n",
      "Due to step prep marked            :  2222 words in   5825 occurrences\n",
      "Due to step prep unmarked          :  2112 words in  14263 occurrences\n",
      "Due to step prep all               :  2222 words in  20088 occurrences\n",
      "After  step prep                   :  4010 words in  23245 occurrences\n",
      "----------------------------------------\n",
      "Before step logo                   :  4010 words in  23245 occurrences\n",
      "Due to step logo marked            :  1616 words in  11647 occurrences\n",
      "Due to step logo unmarked          :  1572 words in   3593 occurrences\n",
      "Due to step logo all               :  1616 words in  15240 occurrences\n",
      "After  step logo                   :  4762 words in  26582 occurrences\n",
      "----------------------------------------\n",
      "Before step num                    :  4762 words in  26582 occurrences\n",
      "Due to step num marked             :    47 words in   2238 occurrences\n",
      "Due to step num unmarked           :     0 words in      0 occurrences\n",
      "Due to step num all                :    47 words in   2238 occurrences\n",
      "After  step num                    :  4767 words in  26599 occurrences\n",
      "----------------------------------------\n",
      "noun          with  4767 words and  26599 occurrences\n",
      "nounMdet      with  2088 words and   6173 occurrences\n",
      "nounMlogo     with  1616 words and  11647 occurrences\n",
      "nounMnum      with    47 words and   2238 occurrences\n",
      "nounMprep     with  2222 words and   5825 occurrences\n",
      "nounUdet      with   290 words and   1920 occurrences\n",
      "nounUlogo     with  1572 words and   3593 occurrences\n",
      "nounUnum      with     0 words and      0 occurrences\n",
      "nounUprep     with  2112 words and  14263 occurrences\n",
      "noundet       with  2378 words and   8093 occurrences\n",
      "nounlogo      with  1616 words and  15240 occurrences\n",
      "nounnum       with    47 words and   2238 occurrences\n",
      "nounprep      with  2222 words and  20088 occurrences\n"
     ]
    }
   ],
   "source": [
    "PT.doNouns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData = {\n",
    "  '': COLOPHON,\n",
    "  'pos': {\n",
    "    'valueType': 'str',\n",
    "    'description': 'primary part-of-speech category on full words',\n",
    "  },\n",
    "  'subpos': {\n",
    "    'valueType': 'str',\n",
    "    'description': 'secondary category within part-of-speech on full words',\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "---\n",
       "\n",
       "## Features\n",
       "\n",
       "**2 TF features saved: pos, subpos**.\n",
       "\n",
       "9 categories.\n",
       "\n",
       "category | % | number of nodes\n",
       "--- | --- | ---\n",
       "none | 47 | 36091\n",
       "all | 53 | 40414\n",
       "noun- | 32 | 24552\n",
       "prep- | 8 | 5943\n",
       "pcl-conj | 3 | 2570\n",
       "pcl-rel | 3 | 2363\n",
       "noun-numeral | 3 | 2238\n",
       "pcl-neg | 2 | 1909\n",
       "adv-tmp | 1 | 399\n",
       "pcl- | 1 | 388\n",
       "prn-dem | 0 | 52\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "---\n",
       "\n",
       "## sets\n",
       "\n",
       "**21 sets written to disk (GitHub repo and Dropbox)**.\n",
       "\n",
       "set | number of nodes\n",
       "--- | ---\n",
       "advtmp | 399\n",
       "nonprep | 70562\n",
       "noun | 26599\n",
       "nounMdet | 6173\n",
       "nounMlogo | 11647\n",
       "nounMnum | 2238\n",
       "nounMprep | 5825\n",
       "nounUdet | 1920\n",
       "nounUlogo | 3593\n",
       "nounUnum | 0\n",
       "nounUprep | 14263\n",
       "noundet | 8093\n",
       "nounlogo | 15240\n",
       "nounnum | 2238\n",
       "nounprep | 20088\n",
       "pcl | 388\n",
       "pclconj | 2570\n",
       "pclneg | 1909\n",
       "pclrel | 2363\n",
       "prep | 5943\n",
       "prndem | 52\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PT.export(metaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "For now, you can make use of a bunch of sets in your queries, whether in the TF-browser or in a notebook.\n",
    "\n",
    "## Getting the sets\n",
    "\n",
    "Here is how you can get the sets.\n",
    "\n",
    "### With Dropbox\n",
    "\n",
    "If you are synchronized to the `obb` shared folder on Dropbox\n",
    "(that means, you have installed the Dropbox client and accepted the invitation to `obb`):\n",
    "\n",
    "You are all set, you have the newest version of the sets file on your computer seconds after\n",
    "it has been updated.\n",
    "\n",
    "### With Github\n",
    "\n",
    "First get the tutorials repo:\n",
    "\n",
    "For the first time:\n",
    "\n",
    "```sh\n",
    "cd ~/github/annotation\n",
    "git clone https://github.com/annotation/tutorials\n",
    "```\n",
    "\n",
    "Advice: do not work in your clone directly, but in a working directory outside this clone.\n",
    "When you want to get updates the repo:\n",
    "\n",
    "```sh\n",
    "cd ~/github/annotation/tutorials\n",
    "git pull origin master\n",
    "```\n",
    "\n",
    "(This will fail if you have worked inside your clone).\n",
    "\n",
    "## Using the sets and features\n",
    "\n",
    "You can use the sets and features directly in your programs, or in TF-queries, whether in notebooks or in the TF-browser.\n",
    "\n",
    "### TF-browser\n",
    "\n",
    "The start the TF browser as follows:\n",
    "\n",
    "```sh\n",
    "text-fabric oldbabylonian --sets=~/Dropbox/obb/sets.tfx --mod=annotation/tutorials/oldbabylonian/cookbook/pos/tf'\n",
    "```\n",
    "\n",
    "or \n",
    "\n",
    "```sh\n",
    "text-fabric oldbabylonian --sets=~/github/annotation/tutorials/oldbabylonian/cookbook/data/sets.tfx --mod=annotation/tutorials/oldbabylonian/cookbook/pos/tf'\n",
    "```\n",
    "\n",
    "### In queries\n",
    "\n",
    "You can load the new features as follows:\n",
    "\n",
    "```python\n",
    "A = use('oldbabylonian', hoist=globals(), mod='annotation/tutorials/oldbabylonian/cookbook/pos/tf')\n",
    "```\n",
    "\n",
    "You can use the names of sets in all places where you currently use `word`, `sign`, `face`, etc.\n",
    "More info in the [docs](https://annotation.github.io/text-fabric/Use/Search/#search-template-reference).\n",
    "\n",
    "As an example, we have used a few sets already in this notebook in order to find the words immediately\n",
    "following a preposition, without being a preposition themselves.\n",
    "\n",
    "If you are running queries in a notebook, you can import the set by means of\n",
    "[readSets](https://annotation.github.io/text-fabric/Api/Lib/#sets):\n",
    "\n",
    "```python\n",
    "sets = readSets('~/Dropbox/obb/sets.tfx')\n",
    "```\n",
    "\n",
    "And then in queries:\n",
    "\n",
    "```python\n",
    "results = A.search('''\n",
    "prep\n",
    ":> nonprep\n",
    "''', sets=sets)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
