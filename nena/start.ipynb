{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/tf.png\" width=\"128\"/>\n",
    "<img align=\"right\" src=\"images/logo.png\" width=\"128\"/>\n",
    "<img align=\"right\" src=\"images/dans.png\" width=\"128\"/>\n",
    "\n",
    "# Tutorial\n",
    "\n",
    "This notebook gets you started with using\n",
    "[Text-Fabric](https://annotation.github.io/text-fabric/) for coding in NENA, a Neo Aramaic Corpus maintained at \n",
    "Cambridge University.\n",
    "\n",
    "Chances are that a bit of reading about the underlying\n",
    "[data model](https://annotation.github.io/text-fabric/Model/Data-Model/)\n",
    "helps you to follow the exercises below, and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Text-Fabric\n",
    "\n",
    "### Python\n",
    "\n",
    "You need to have Python on your system. Most systems have it out of the box,\n",
    "but alas, that is python2 and we need at least python **3.6**.\n",
    "\n",
    "Install it from [python.org](https://www.python.org) or from\n",
    "[Anaconda](https://www.anaconda.com/download).\n",
    "\n",
    "### TF itself\n",
    "\n",
    "```\n",
    "pip3 install text-fabric\n",
    "```\n",
    "\n",
    "### Jupyter notebook\n",
    "\n",
    "You need [Jupyter](http://jupyter.org).\n",
    "\n",
    "If it is not already installed:\n",
    "\n",
    "```\n",
    "pip3 install jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip\n",
    "If you cloned the repository containing this tutorial,\n",
    "first copy its parent directory to somewhere outside your clone of the repo,\n",
    "before computing with this it.\n",
    "\n",
    "If you pull changes from the repository later, it will not conflict with\n",
    "your computations.\n",
    "\n",
    "Where you put your tutorial directory is up to you.\n",
    "It will work from any directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cookbook\n",
    "\n",
    "This tutorial and its sister tutorials are meant to showcase most of things TF can do.\n",
    "\n",
    "But we also have a [cookbook](cookbook) with a set of focused recipes on tricky things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Text-Fabric will fetch the data set for you from github, and check for updates.\n",
    "\n",
    "The data will be stored in the `text-fabric-data` in your home directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "The data of the corpus is organized in features.\n",
    "They are *columns* of data.\n",
    "Think of the corpus as a gigantic spreadsheet, where row 1 corresponds to the\n",
    "first sign, row 2 to the second sign, and so on, for all ~ 1.5 M signs,\n",
    "followed by ~ 500 K word nodes and yet another 200 K nodes of other types.\n",
    "\n",
    "The information which reading each sign has, constitutes a column in that spreadsheet.\n",
    "The DSS corpus contains > 50 columns.\n",
    "\n",
    "Instead of putting that information in one big table, the data is organized in separate columns.\n",
    "We call those columns **features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:16.202764Z",
     "start_time": "2018-05-18T09:17:16.197546Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incantation\n",
    "\n",
    "The simplest way to get going is by this *incantation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:17.537171Z",
     "start_time": "2018-05-18T09:17:17.517809Z"
    }
   },
   "outputs": [],
   "source": [
    "from tf.app import use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rate limit is 5000 requests per hour, with 4988 left for this hour\n",
      "\tconnecting to online GitHub repo annotation/app-nena ... connected\n",
      "Using TF-app in /Users/dirk/text-fabric-data/annotation/app-nena/code:\n",
      "\trv0.011=#9ec58f223a6ba6817347279da277c1efadae550a (latest commit)\n",
      "rate limit is 5000 requests per hour, with 4985 left for this hour\n",
      "\tconnecting to online GitHub repo CambridgeSemiticsLab/nena_tf ... connected\n",
      "Using data in /Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01:\n",
      "\t#87442f2654833a85ff4772bf3586bf1e8b4f38e8 (latest commit)\n",
      "   |     0.00s No structure info in otext, the structure part of the T-API cannot be used\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Documentation:</b> <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs\" title=\"provenance of Northeastern Neo-Aramaic Text Corpus\">NENA_TF</a> <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/transcription.md\" title=\"('NENA transcription script',)\">Character table</a> <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#features.md\" title=\"NENA_TF feature documentation\">Feature docs</a> <a target=\"_blank\" href=\"https://github.com/annotation/app-nena\" title=\"nena API documentation\">nena API</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/\" title=\"text-fabric-api\">Text-Fabric API 7.10.2</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Use/Search/\" title=\"Search Templates Introduction and Reference\">Search Reference</a><details open><summary><b>Loaded features</b>:</summary>\n",
       "<p><b>Northeastern Neo-Aramaic Text Corpus</b>: <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#class\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/class.tf\">class</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#comment\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/comment.tf\">comment</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#continued_from\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/continued_from.tf\">continued_from</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#dialect\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/dialect.tf\">dialect</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#end\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/end.tf\">end</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#footnotes\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/footnotes.tf\">footnotes</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#foreign\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/foreign.tf\">foreign</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#full\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/full.tf\">full</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#full_end\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/full_end.tf\">full_end</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#fuzzy\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/fuzzy.tf\">fuzzy</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#fuzzy_end\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/fuzzy_end.tf\">fuzzy_end</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#gloss\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/gloss.tf\">gloss</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#grm_desc\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/grm_desc.tf\">grm_desc</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#informant\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/informant.tf\">informant</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#lang\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/lang.tf\">lang</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#lemma\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/lemma.tf\">lemma</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#lemma_form\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/lemma_form.tf\">lemma_form</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#lite\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/lite.tf\">lite</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#lite_end\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/lite_end.tf\">lite_end</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#number\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/number.tf\">number</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#otype\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/otype.tf\">otype</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#place\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/place.tf\">place</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#source\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/source.tf\">source</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#speaker\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/speaker.tf\">speaker</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#text\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/text.tf\">text</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#text_id\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/text_id.tf\">text_id</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#text_norm\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/text_norm.tf\">text_norm</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#title\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/title.tf\">title</a>  <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#version\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/version.tf\">version</a>  <b><i><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#oslots\" title=\"/Users/dirk/text-fabric-data/CambridgeSemiticsLab/nena_tf/tf/0.01/oslots.tf\">oslots</a></i></b> </p></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@font-face {\n",
       "  font-family: \"CharisSIL-R\";\n",
       "  src:\n",
       "    local(\"CharisSIL-R.otf\"),\n",
       "    url(\"https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/CharisSIL-R.woff?raw=true\");\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: normal;\n",
       "    color: #000000;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    direction: ltr;\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 0.1em 0em;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-style: italic;\n",
       "  font-size: x-small;\n",
       "  font-weight: normal;\n",
       "}\n",
       "\n",
       ".ll {\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-end;\n",
       "    align-items: flex-end;\n",
       "    direction: ltr;\n",
       "    width: 100%;\n",
       "}\n",
       "\n",
       ".outeritem {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: ltr;\n",
       "}\n",
       "\n",
       ".word,.micro,.macro {\n",
       "    border: 1px solid #4f4c4c;\n",
       "    border-radius: 0.2em;\n",
       "    border-spacing: 5px;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.4em;\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: ltr;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       "\n",
       ".prosa {\n",
       "    border: 1.5px dotted #4f4c4c;\n",
       "    border-radius: 0.2em;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.4em;\n",
       "    border-color: #a30404;\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: ltr;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       "\n",
       "\n",
       ".line {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: ltr;\n",
       "}\n",
       "\n",
       ".ln {\n",
       "  font-size: small !important;\n",
       "  padding-right: 1em;\n",
       "}\n",
       "\n",
       ".nd {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #999999;\n",
       "}\n",
       "\n",
       ".hl {\n",
       "    background-color: #ffee66;\n",
       "}\n",
       "\n",
       ".ara,.ara a:visited,.ara a:link {\n",
       "    font-family: \"CharisSIL-R\";\n",
       "    font-size: 12pt;\n",
       "    color: #000000;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       "\n",
       "/* What do the following classes do? */\n",
       "\n",
       ".tr,.tr a:visited,.tr a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".trb,.trb a:visited,.trb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: normal;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       "\n",
       ".occs {\n",
       "    font-size: x-small;\n",
       "}\n",
       "\n",
       "tr.tf, td.tf, th.tf {\n",
       "  text-align: left;\n",
       "}\n",
       "\n",
       "span.hldot {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder: 0.2rem solid var(--hl-rim);\n",
       "\tborder-radius: 0.4rem;\n",
       "\t/*\n",
       "\tdisplay: inline-block;\n",
       "\twidth: 0.8rem;\n",
       "\theight: 0.8rem;\n",
       "\t*/\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "\n",
       "span.hlup {\n",
       "\tborder-color: var(--hl-dark);\n",
       "\tborder-width: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 0.2rem;\n",
       "  padding: 0.2rem;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55, 100%,  60%, 0.9  );\n",
       "\t--hl-dark:          hsla( 55, 100%,  40%, 0.9  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<details open><summary><b>API members</b>:</summary>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Computed/#computed-data\" title=\"doc\">C Computed</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Computed/#computed-data\" title=\"doc\">Call AllComputeds</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Computed/#computed-data\" title=\"doc\">Cs ComputedString</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#edge-features\" title=\"doc\">E Edge</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#edge-features\" title=\"doc\">Eall AllEdges</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#edge-features\" title=\"doc\">Es EdgeString</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">ensureLoaded</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">TF</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">ignored</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">loadLog</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Locality/#locality\" title=\"doc\">L Locality</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">cache</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">error</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">indent</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">info</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">isSilent</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">reset</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">setSilent</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">silentOff</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">silentOn</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">warning</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">N Nodes</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">sortKey</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">sortKeyTuple</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">otypeRank</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">sortNodes</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#node-features\" title=\"doc\">F Feature</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#node-features\" title=\"doc\">Fall AllFeatures</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#node-features\" title=\"doc\">Fs FeatureString</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Search/#search\" title=\"doc\">S Search</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Text/#text\" title=\"doc\">T Text</a></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = use('nena:hot', checkout='hot', hoist=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see which features have been loaded, and if you click on a feature name, you find its documentation.\n",
    "If you hover over a name, you see where the feature is located on your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API\n",
    "\n",
    "The result of the incantation is that we have a bunch of special variables at our disposal\n",
    "that give us access to the text and data of the corpus.\n",
    "\n",
    "At this point it is helpful to throw a quick glance at the text-fabric API documentation\n",
    "(see the links under **API Members** above).\n",
    "\n",
    "The most essential thing for now is that we can use `F` to access the data in the features\n",
    "we've loaded.\n",
    "But there is more, such as `N`, which helps us to walk over the text, as we see in a minute.\n",
    "\n",
    "The **API members** above show you exactly which new names have been inserted in your namespace.\n",
    "If you click on these names, you go to the API documentation for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "Text-Fabric contains a flexible search engine, that does not only work for the data,\n",
    "of this corpus, but also for other corpora and data that you add to corpora.\n",
    "\n",
    "**Search is the quickest way to come up-to-speed with your data, without too much programming.**\n",
    "\n",
    "Jump to the dedicated [search](search.ipynb) search tutorial first, to whet your appetite.\n",
    "\n",
    "The real power of search lies in the fact that it is integrated in a programming environment.\n",
    "You can use programming to:\n",
    "\n",
    "* compose dynamic queries\n",
    "* process query results\n",
    "\n",
    "Therefore, the rest of this tutorial is still important when you want to tap that power.\n",
    "If you continue here, you learn all the basics of data-navigation with Text-Fabric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting\n",
    "\n",
    "In order to get acquainted with the data, we start with the simple task of counting.\n",
    "\n",
    "## Count all nodes\n",
    "We use the \n",
    "[`N()` generator](https://annotation.github.io/text-fabric/Api/General/#navigating-nodes)\n",
    "to walk through the nodes.\n",
    "\n",
    "We compared the TF data to a gigantic spreadsheet, where the rows correspond to the signs.\n",
    "In Text-Fabric, we call the rows `slots`, because they are the textual positions that can be filled with signs.\n",
    "\n",
    "We also mentioned that there are also other textual objects. \n",
    "They are the clusters, lines, faces and documents.\n",
    "They also correspond to rows in the big spreadsheet.\n",
    "\n",
    "In Text-Fabric we call all these rows *nodes*, and the `N()` generator\n",
    "carries us through those nodes in the textual order.\n",
    "\n",
    "Just one extra thing: the `info` statements generate timed messages.\n",
    "If you use them instead of `print` you'll get a sense of the amount of time that \n",
    "the various processing steps typically need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "silentOff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:43.894153Z",
     "start_time": "2018-05-18T09:17:43.597128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Counting nodes ...\n",
      "  0.13s 833532 nodes\n"
     ]
    }
   ],
   "source": [
    "indent(reset=True)\n",
    "info('Counting nodes ...')\n",
    "\n",
    "i = 0\n",
    "for n in N(): i += 1\n",
    "\n",
    "info('{} nodes'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see it: a bit less than 1M nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are those nodes?\n",
    "Every node has a type, like sign, or line, face.\n",
    "But what exactly are they?\n",
    "\n",
    "Text-Fabric has two special features, `otype` and `oslots`, that must occur in every Text-Fabric data set.\n",
    "`otype` tells you for each node its type, and you can ask for the number of `slot`s in the text.\n",
    "\n",
    "Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:47.820323Z",
     "start_time": "2018-05-18T09:17:47.812328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'letter'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.slotType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:48.549430Z",
     "start_time": "2018-05-18T09:17:48.543371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "539381"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.maxSlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:49.251302Z",
     "start_time": "2018-05-18T09:17:49.244467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "833532"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.maxNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:49.922863Z",
     "start_time": "2018-05-18T09:17:49.916078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dialect',\n",
       " 'text',\n",
       " 'paragraph',\n",
       " 'line',\n",
       " 'sentence',\n",
       " 'subsentence',\n",
       " 'inton',\n",
       " 'word',\n",
       " 'morpheme',\n",
       " 'letter')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:51.782779Z",
     "start_time": "2018-05-18T09:17:51.774167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('dialect', 269690.5, 539382, 539383),\n",
       " ('text', 4280.8015873015875, 739645, 739770),\n",
       " ('paragraph', 1536.6980056980058, 698060, 698410),\n",
       " ('line', 212.02083333333334, 575368, 577911),\n",
       " ('sentence', 32.28473095109834, 698411, 715117),\n",
       " ('subsentence', 21.991315692909854, 715118, 739644),\n",
       " ('inton', 14.989467541129391, 539384, 575367),\n",
       " ('word', 5.752660992726264, 739771, 833532),\n",
       " ('morpheme', 4.489304857342611, 577912, 698059),\n",
       " ('letter', 1, 1, 539381))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.levels.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting: above you see all the textual objects, with the average size of their objects,\n",
    "the node where they start, and the node where they end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count individual object types\n",
    "This is an intuitive way to count the number of nodes in each type.\n",
    "Note in passing, how we use the `indent` in conjunction with `info` to produce neat timed \n",
    "and indented progress messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:57.806821Z",
     "start_time": "2018-05-18T09:17:57.558523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s counting objects ...\n",
      "   |     0.00s       2 dialects\n",
      "   |     0.00s     126 texts\n",
      "   |     0.00s     351 paragraphs\n",
      "   |     0.00s    2544 lines\n",
      "   |     0.00s   16707 sentences\n",
      "   |     0.00s   24527 subsentences\n",
      "   |     0.00s   35984 intons\n",
      "   |     0.01s   93762 words\n",
      "   |     0.02s  120148 morphemes\n",
      "   |     0.06s  539381 letters\n",
      "  0.10s Done\n"
     ]
    }
   ],
   "source": [
    "indent(reset=True)\n",
    "info('counting objects ...')\n",
    "\n",
    "for otype in F.otype.all:\n",
    "    i = 0\n",
    "\n",
    "    indent(level=1, reset=True)\n",
    "\n",
    "    for n in F.otype.s(otype): i+=1\n",
    "\n",
    "    info('{:>7} {}s'.format(i, otype))\n",
    "\n",
    "indent(level=0)\n",
    "info('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing textual objects\n",
    "\n",
    "You can use the A API (the extra power) to display cuneiform text.\n",
    "\n",
    "See the [display](display.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature statistics\n",
    "\n",
    "`F`\n",
    "gives access to all features.\n",
    "Every feature has a method\n",
    "`freqList()`\n",
    "to generate a frequency list of its values, higher frequencies first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:18.039544Z",
     "start_time": "2018-05-18T09:18:17.784073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('Dawið ʾAdam', 36998),\n",
       " ('Yulia Davudi', 34700),\n",
       " ('Yuwarəš Xošăba Kena', 17558),\n",
       " ('Manya Givoyev', 12519),\n",
       " ('Yuwəl Yuḥanna', 10344),\n",
       " ('Yosəp bet Yosəp', 9570),\n",
       " ('Nanəs Bənyamən', 9252),\n",
       " ('Yonan Petrus', 8446),\n",
       " ('Natan Khoshaba', 8192),\n",
       " ('Merab Badalov', 6279),\n",
       " ('Arsen Mikhaylov', 5979),\n",
       " ('Nancy George', 5805),\n",
       " ('Alice Bet-Yosəp', 5796),\n",
       " ('Xošebo ʾOdišo', 5726),\n",
       " ('Maryam Gwirgis', 5474),\n",
       " ('Awiko Sulaqa', 5449),\n",
       " ('Bənyamən Bənyamən', 4499),\n",
       " ('Nadia Aloverdova', 3293),\n",
       " ('Mišayel Barčəm', 3180),\n",
       " ('Frederic Ayyubkhan', 2906),\n",
       " ('Victor Orshan', 2502),\n",
       " ('Sophia Danielova', 2012),\n",
       " ('Blandina Barwari', 1774),\n",
       " ('Dawið Gwərgəs', 1506),\n",
       " ('Jacob Petrus', 1388),\n",
       " ('Gwərgəs Dawið', 1129),\n",
       " ('Dawid Adam', 850),\n",
       " ('Kena Kena', 306),\n",
       " ('GK', 184),\n",
       " ('Nawiya ʾOdišo', 172),\n",
       " ('Leya ʾOraha', 122))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.speaker.freqList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words and morphemes have the feature `foreign`. We can count them separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:18.039544Z",
     "start_time": "2018-05-18T09:18:17.784073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('True', 507),)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.foreign.freqList('word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:18.039544Z",
     "start_time": "2018-05-18T09:18:17.784073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('True', 534),)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.foreign.freqList('morpheme')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word matters\n",
    "\n",
    "## Top 20 frequent words\n",
    "\n",
    "We count words by their lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2811 w, ʾu-\n",
      " 1712 ṱ\n",
      " 1532 xa, xaʾa\n",
      " 1261 b-\n",
      " 1234 la\n",
      " 1003 gu-\n",
      "  965 ʾana\n",
      "  830 l-\n",
      "  823 diya\n",
      "  814 t\n",
      "  722 mən, m-\n",
      "  649 ʾawwa\n",
      "  621 qəm-\n",
      "  595 malka\n",
      "  588 kul, ku, kulla\n",
      "  560 mo, mu, modi, maw, mawdi\n",
      "  531 tama\n",
      "  524 naša\n",
      "  516 ʾaw\n",
      "  502 hatxa, ʾatxa\n"
     ]
    }
   ],
   "source": [
    "for (w, amount) in F.lemma.freqList()[0:20]:\n",
    "  print(f'{amount:>5} {w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word distribution\n",
    "\n",
    "Let's do a bit more fancy word stuff.\n",
    "\n",
    "### Hapaxes\n",
    "\n",
    "A hapax can be found by picking the words with frequency 1.\n",
    "\n",
    "We print 20 hapaxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1470"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapaxes1 = sorted(lx for (lx, amount) in F.lemma.freqList() if amount == 1)\n",
    "len(hapaxes1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b- bahs, bas\n",
      "b- dargušta\n",
      "b- dudəkθa\n",
      "b- ga\n",
      "b- gare\n",
      "b- gawza\n",
      "b- gawṛa, gʸawṛa\n",
      "b- guda\n",
      "b- ham\n",
      "b- ho\n",
      "b- kawe xa, xaʾa\n",
      "b- lawurta\n",
      "b- linta\n",
      "b- panjăra, panjara, panjɛra, panjăriya, panjăriye\n",
      "b- pumma\n",
      "b- pəlxana\n",
      "b- pəṣla\n",
      "b- qðala\n",
      "b- qɛma\n",
      "b- rapəkθa\n"
     ]
    }
   ],
   "source": [
    "for lx in hapaxes1[0:20]:\n",
    "  print(lx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small occurrence base\n",
    "\n",
    "The occurrence base of a word are the scrolls in which occurs.\n",
    "\n",
    "We compute the occurrence base of each word, based on lexemes according to the `glex` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s compiling occurrence base ...\n",
      "  1.86s 3142 entries\n"
     ]
    }
   ],
   "source": [
    "occurrenceBase1 = collections.defaultdict(set)\n",
    "\n",
    "indent(reset=True)\n",
    "info('compiling occurrence base ...')\n",
    "for w in F.otype.s('word'):\n",
    "  text = T.sectionFromNode(w)[1]\n",
    "  occurrenceBase1[F.lemma.v(w)].add(text)\n",
    "info(f'{len(occurrenceBase1)} entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that took long!\n",
    "\n",
    "We looked up the text for each word.\n",
    "\n",
    "But there is another way:\n",
    "\n",
    "Start with texts, and iterate through their words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s compiling occurrence base ...\n",
      "  0.18s done\n",
      "  0.18s 3142 entries\n"
     ]
    }
   ],
   "source": [
    "occurrenceBase2 = collections.defaultdict(set)\n",
    "\n",
    "indent(reset=True)\n",
    "info('compiling occurrence base ...')\n",
    "for s in F.otype.s('text'):\n",
    "  text = F.title.v(s)\n",
    "  for w in L.d(s, otype='word'):\n",
    "    occurrenceBase2[F.lemma.v(w)].add(text)\n",
    "info('done')\n",
    "info(f'{len(occurrenceBase2)} entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. Are the results equal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occurrenceBase1 == occurrenceBase2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrenceBase = occurrenceBase2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of how many words have how big occurrence bases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base size    1 :  2033 words\n",
      "base size    2 :   439 words\n",
      "base size    3 :   172 words\n",
      "base size    4 :   114 words\n",
      "base size    5 :    67 words\n",
      "base size    7 :    43 words\n",
      "base size    6 :    40 words\n",
      "base size   10 :    26 words\n",
      "base size    9 :    20 words\n",
      "base size    8 :    18 words\n",
      "...\n",
      "base size   26 :     1 words\n",
      "base size   31 :     1 words\n",
      "base size   33 :     1 words\n",
      "base size   34 :     1 words\n",
      "base size   36 :     1 words\n",
      "base size   44 :     1 words\n",
      "base size   45 :     1 words\n",
      "base size   50 :     1 words\n",
      "base size   51 :     1 words\n",
      "base size  126 :     1 words\n"
     ]
    }
   ],
   "source": [
    "occurrenceSize = collections.Counter()\n",
    "\n",
    "for (w, scrolls) in occurrenceBase.items():\n",
    "  occurrenceSize[len(scrolls)] += 1\n",
    "  \n",
    "occurrenceSize = sorted(\n",
    "  occurrenceSize.items(),\n",
    "  key=lambda x: (-x[1], x[0]),\n",
    ")\n",
    "\n",
    "for (size, amount) in occurrenceSize[0:10]:\n",
    "  print(f'base size {size:>4} : {amount:>5} words')\n",
    "print('...')\n",
    "for (size, amount) in occurrenceSize[-10:]:\n",
    "  print(f'base size {size:>4} : {amount:>5} words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give the predicate *private* to those words whose occurrence base is a single text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2033"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privates = {w for (w, base) in occurrenceBase.items() if len(base) == 1}\n",
    "len(privates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peculiarity of texts\n",
    "\n",
    "As a final exercise with texts, lets make a list of all texts, and show their\n",
    "\n",
    "* total number of words\n",
    "* number of private words\n",
    "* the percentage of private words: a measure of the peculiarity of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:52.143337Z",
     "start_time": "2018-05-18T09:18:52.130385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found    0 empty texts\n",
      "Found   74 ordinary texts (i.e. without private words)\n"
     ]
    }
   ],
   "source": [
    "textList = []\n",
    "\n",
    "empty = set()\n",
    "ordinary = set()\n",
    "\n",
    "for d in F.otype.s('text'):\n",
    "  text = F.title.v(d)\n",
    "  words = {F.lemma.v(w) for w in L.d(d, otype='word')}\n",
    "  a = len(words)\n",
    "  if not a:\n",
    "    empty.add(text)\n",
    "    continue\n",
    "  o = len({w for w in words if w in privates})\n",
    "  if not o:\n",
    "    ordinary.add(text)\n",
    "    continue\n",
    "  p = 100 * o / a\n",
    "  textList.append((text, a, o, p))\n",
    "\n",
    "textList = sorted(textList, key=lambda e: (-e[3], -e[1], e[0]))\n",
    "\n",
    "print(f'Found {len(empty):>4} empty texts')\n",
    "print(f'Found {len(ordinary):>4} ordinary texts (i.e. without private words)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:52.143337Z",
     "start_time": "2018-05-18T09:18:52.130385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                                               #all #own %own\n",
      "-----------------------------------\n",
      "Gozali and Nozali                                   612  232 37.9%\n",
      "The Crow and the Cheese                              26    8 30.8%\n",
      "The Crafty Hireling                                 261   74 28.4%\n",
      "The Tale of Mămo and Zine                           452  125 27.7%\n",
      "Tales From the 1001 Nights                          517  139 26.9%\n",
      "A Tale of a Prince and a Princess                   335   88 26.3%\n",
      "Baby Leliθa                                         225   59 26.2%\n",
      "The Priest and the Mullah                           100   26 26.0%\n",
      "The Tale of Parizada, Warda and Nargis              388   97 25.0%\n",
      "The Tale of Rustam (2)                              309   76 24.6%\n",
      "The Tale of Farxo and Səttiya                       426  104 24.4%\n",
      "The Man Who Wanted to Work                          218   53 24.3%\n",
      "The Girl and the Seven Brothers                     194   47 24.2%\n",
      "A Hundred Gold Coins                                114   27 23.7%\n",
      "The Story With No End                                60   14 23.3%\n",
      "The King With Forty Sons                            406   94 23.2%\n",
      "The Selfish Neighbour                                58   13 22.4%\n",
      "The Bear and the Fox                                119   26 21.8%\n",
      "The Sale of an Ox                                   251   52 20.7%\n",
      "Man Is Treacherous                                   73   15 20.5%\n",
      "...\n",
      "The Tale of Mərza Pămət                             245   44 18.0%\n",
      "The Fox and the Stork                                39    7 17.9%\n",
      "The Sisisambər Plant                                 91   16 17.6%\n",
      "The Wise Young Man                                  245   43 17.6%\n",
      "The Monk and the Angel                              176   30 17.0%\n",
      "A Tale of Two Kings                                 141   24 17.0%\n",
      "The Battle With Yuwanəs the Armenian                143   24 16.8%\n",
      "The Lion With a Swollen Leg                         102   17 16.7%\n",
      "Measure for Measure                                  43    7 16.3%\n",
      "The Tale of Rustam (1)                              196   30 15.3%\n",
      "The Leliθa From č̭āl                                 91   13 14.3%\n",
      "The Cat and the Mice                                 35    5 14.3%\n",
      "The Lion King                                        43    6 14.0%\n",
      "The Cooking Pot                                      72   10 13.9%\n",
      "I Am Worth the Same as a Blind Wolf                 137   19 13.9%\n",
      "The Monk Who Wanted to Know When He Would Die       110   15 13.6%\n",
      "The Tale of Nasimo                                  118   15 12.7%\n",
      "The Giant’s Cave                                     88   11 12.5%\n",
      "The Scorpion and the Snake                           70    8 11.4%\n",
      "The Man Who Cried Wolf                               68    6  8.8%\n"
     ]
    }
   ],
   "source": [
    "print('{:<50}{:>5}{:>5}{:>5}\\n{}'.format(\n",
    "    'text', '#all', '#own', '%own',\n",
    "    '-'*35,\n",
    "))\n",
    "\n",
    "for x in textList[0:20]:\n",
    "  print('{:<50} {:>4} {:>4} {:>4.1f}%'.format(*x))\n",
    "print('...')\n",
    "for x in textList[-20:]:\n",
    "  print('{:<50} {:>4} {:>4} {:>4.1f}%'.format(*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locality API\n",
    "We travel upwards and downwards, forwards and backwards through the nodes.\n",
    "The Locality-API (`L`) provides functions: `u()` for going up, and `d()` for going down,\n",
    "`n()` for going to next nodes and `p()` for going to previous nodes.\n",
    "\n",
    "These directions are indirect notions: nodes are just numbers, but by means of the\n",
    "`oslots` feature they are linked to slots. One node *contains* an other node, if the one is linked to a set of slots that contains the set of slots that the other is linked to.\n",
    "And one if next or previous to an other, if its slots follow or precede the slots of the other one.\n",
    "\n",
    "`L.u(node)` **Up** is going to nodes that embed `node`.\n",
    "\n",
    "`L.d(node)` **Down** is the opposite direction, to those that are contained in `node`.\n",
    "\n",
    "`L.n(node)` **Next** are the next *adjacent* nodes, i.e. nodes whose first slot comes immediately after the last slot of `node`.\n",
    "\n",
    "`L.p(node)` **Previous** are the previous *adjacent* nodes, i.e. nodes whose last slot comes immediately before the first slot of `node`.\n",
    "\n",
    "All these functions yield nodes of all possible otypes.\n",
    "By passing an optional parameter, you can restrict the results to nodes of that type.\n",
    "\n",
    "The result are ordered according to the order of things in the text.\n",
    "\n",
    "The functions return always a tuple, even if there is just one node in the result.\n",
    "\n",
    "## Going up\n",
    "We go from the first word to the scroll it contains.\n",
    "Note the `[0]` at the end. You expect one scroll, yet `L` returns a tuple. \n",
    "To get the only element of that tuple, you need to do that `[0]`.\n",
    "\n",
    "If you are like me, you keep forgetting it, and that will lead to weird error messages later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:55.410034Z",
     "start_time": "2018-05-18T09:18:55.404051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739645\n"
     ]
    }
   ],
   "source": [
    "firstText = L.u(1, otype='text')[0]\n",
    "print(firstText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's see all the containing objects of letter 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:56.772513Z",
     "start_time": "2018-05-18T09:18:56.766324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter 3 is contained in dialect 539382\n",
      "letter 3 is contained in text 739645\n",
      "letter 3 is contained in paragraph 698060\n",
      "letter 3 is contained in line 575368\n",
      "letter 3 is contained in sentence 698411\n",
      "letter 3 is contained in subsentence 715118\n",
      "letter 3 is contained in inton 539384\n",
      "letter 3 is contained in word 739771\n",
      "letter 3 is contained in morpheme 577913\n"
     ]
    }
   ],
   "source": [
    "s = 3\n",
    "for otype in F.otype.all:\n",
    "  if otype == F.otype.slotType: continue\n",
    "  up = L.u(s, otype=otype)\n",
    "  upNode = 'x' if len(up) == 0 else up[0]\n",
    "  print('letter {} is contained in {} {}'.format(s, otype, upNode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going next\n",
    "Let's go to the next nodes of the first text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:58.821681Z",
     "start_time": "2018-05-18T09:18:58.814893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2004: letter        first slot=2004  , last slot=2004  \n",
      " 578395: morpheme      first slot=2004  , last slot=2004  \n",
      " 740114: word          first slot=2004  , last slot=2012  \n",
      " 539513: inton         first slot=2004  , last slot=2029  \n",
      " 715222: subsentence   first slot=2004  , last slot=2029  \n",
      " 698479: sentence      first slot=2004  , last slot=2029  \n",
      " 575380: line          first slot=2004  , last slot=2183  \n",
      " 698061: paragraph     first slot=2004  , last slot=6497  \n",
      " 739646: text          first slot=2004  , last slot=6497  \n"
     ]
    }
   ],
   "source": [
    "afterFirstText = L.n(firstText)\n",
    "for n in afterFirstText:\n",
    "  print('{:>7}: {:<13} first slot={:<6}, last slot={:<6}'.format(\n",
    "      n, F.otype.v(n),\n",
    "      E.oslots.s(n)[0],\n",
    "      E.oslots.s(n)[-1],\n",
    "  ))\n",
    "secondText = L.n(firstText, otype='text')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going previous\n",
    "\n",
    "And let's see what is right before the second text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:00.163973Z",
     "start_time": "2018-05-18T09:19:00.154857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 739645: text          first slot=1     , last slot=2003  \n",
      " 698060: paragraph     first slot=1     , last slot=2003  \n",
      " 575379: line          first slot=1855  , last slot=2003  \n",
      " 698478: sentence      first slot=1985  , last slot=2003  \n",
      " 715221: subsentence   first slot=1985  , last slot=2003  \n",
      " 539512: inton         first slot=1985  , last slot=2003  \n",
      " 740113: word          first slot=1992  , last slot=2003  \n",
      " 578394: morpheme      first slot=1996  , last slot=2003  \n",
      "   2003: letter        first slot=2003  , last slot=2003  \n"
     ]
    }
   ],
   "source": [
    "for n in L.p(secondText):\n",
    "  print('{:>7}: {:<13} first slot={:<6}, last slot={:<6}'.format(\n",
    "      n, F.otype.v(n),\n",
    "      E.oslots.s(n)[0],\n",
    "      E.oslots.s(n)[-1],\n",
    "  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go to the lines of the first text, and just count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:02.530705Z",
     "start_time": "2018-05-18T09:19:02.475279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "lines = L.d(firstText, otype='line')\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text API\n",
    "\n",
    "So far, we have mainly seen nodes and their numbers, and the names of node types.\n",
    "You would almost forget that we are dealing with text.\n",
    "So let's try to see some text.\n",
    "\n",
    "In the same way as `F` gives access to feature data,\n",
    "`T` gives access to the text.\n",
    "That is also feature data, but you can tell Text-Fabric which features are specifically\n",
    "carrying the text, and in return Text-Fabric offers you\n",
    "a Text API: `T`.\n",
    "\n",
    "## Formats\n",
    "DSS text can be represented in a number of ways:\n",
    "\n",
    "* `orig`: unicode\n",
    "* `trans`: ETCBC transcription\n",
    "* `source`: as in Abegg's data files\n",
    "\n",
    "All three can be represented in two flavours:\n",
    "\n",
    "* `full`: all glyphs, but no bracketings and flags\n",
    "* `extra`: everything\n",
    "\n",
    "If you wonder where the information about text formats is stored: \n",
    "not in the program text-fabric, but in the data set.\n",
    "It has a feature `otext`, which specifies the formats and which features\n",
    "must be used to produce them. `otext` is the third special feature in a TF data set,\n",
    "next to `otype` and `oslots`. \n",
    "It is an optional feature. \n",
    "If it is absent, there will be no `T` API.\n",
    "\n",
    "Here is a list of all available formats in this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text-orig-full': 'letter',\n",
       " 'text-trans-full': 'letter',\n",
       " 'text-trans-fuzzy': 'letter',\n",
       " 'text-trans-lite': 'letter'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the formats\n",
    "\n",
    "The ` T.text()` function is central to get text representations of nodes. Its most basic usage is\n",
    "\n",
    "```python\n",
    "T.text(nodes, fmt=fmt)\n",
    "```\n",
    "where `nodes` is a list or iterable of nodes, usually word nodes, and `fmt` is the name of a format.\n",
    "If you leave out `fmt`, the default `text-orig-full` is chosen.\n",
    "\n",
    "The result is the text in that format for all nodes specified:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see for each format in the list above its intended level of operation: `letter` or `word`.\n",
    "\n",
    "If TF formats a node according to a defined text-format, it will descend to constituent nodes and represent those\n",
    "constituent nodes.\n",
    "\n",
    "In this case, no formats specify the `word` level as the descend type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not specify a format, the **default** format is used (`text-orig-full`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We examine a portion of text material:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575541"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineNode = T.nodeFromSection(('Barwar', 'Gozali and Nozali', 8))\n",
    "lineNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "line ('Barwar', 'Gozali and Nozali', 8) with\n",
      "  166 letters\n",
      "   40 morphemes\n",
      "   27 words\n",
      "\n"
     ]
    }
   ],
   "source": [
    "letters = L.d(lineNode, otype='letter')\n",
    "morphemes = L.d(lineNode, otype='morpheme')\n",
    "words = L.d(lineNode, otype='word')\n",
    "print(f'''\n",
    "line {T.sectionFromNode(lineNode)} with\n",
    "  {len(letters):>3} letters\n",
    "  {len(morphemes):>3} morphemes\n",
    "  {len(words):>3} words\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:13.490426Z",
     "start_time": "2018-05-18T09:19:13.486053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hadíya mù wídle?ˈ mə́re ṭlá polìseˈ mə́re só l-bɛ́θət flàn-naša.ˈ sógu'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(letters[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:13.490426Z",
     "start_time": "2018-05-18T09:19:13.486053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hadíya mù wídle?ˈ mə́re ṭlá polìseˈ mə́re só l-bɛ́θət flàn-naša.ˈ sógun l-bɛ́θət flàn-naša,ˈ ʾu-šə́qlula ʾan-'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(morphemes[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:13.490426Z",
     "start_time": "2018-05-18T09:19:13.486053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hadíya mù wídle?ˈ mə́re ṭlá polìseˈ mə́re só l-bɛ́θət flàn-naša.ˈ '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(words[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole text in all formats in a few seconds\n",
    "Part of the pleasure of working with computers is that they can crunch massive amounts of data.\n",
    "\n",
    "We print the text in all formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:27.839331Z",
     "start_time": "2018-05-18T09:19:18.526400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s writing plain text of all texts in all text formats\n",
      "  2.57s done 4 formats\n",
      "text-orig-full\n",
      "xá-ga xèta,ˈ mállah Naṣràdin,ˈ xázəx mòdi wíða.ˈ gu-bɛ̀θa wéwa,ˈ har-zála-w θàya.ˈ zála-w θàya,ˈ mára ya-ʾàlaha,ˈ yawə̀tliˈ ʾə́mma dàwe.ˈ ʾən-hàwaˈ ʾə́č̣č̣i-u ʾə́č̣č̣a maqəlbə̀nna.ˈ ʾu-ʾən-hàwaˈ ʾə́mma-w-xà-ži,ˈ la-băyə̀nna.ˈ de-šùqla.ˈ ʾə̀mma gắrəg háwa drə́st.ˈ \n",
      "b-álaha hóle zála-w θàya,ˈ ʾíθwale xá-šwawa huðàya,ˈ maṣóθe ʾə́lle dìye.ˈ mə́re xázəx ʾáwwa dū̀s-ile.ˈ qɛ́mən mjarbə̀nne.ˈ síqa l-gàre,ˈ də́ryɛle ʾə́č̣č̣i-u ʾə́č̣č̣a dáwe gu-ða-kìsta,ˈ də́rya b-kàwele.ˈ ʾá báxta hàyyo!ˈ hóle ʾaláha qəm-mšadə̀rrən.ˈ \n",
      "muθɛ́θɛla màjma.ˈ msúrqəlla píšela mnáyəlla l-xà-xa.ˈ plíṭla ʾə́č̣č̣i-u ʾə̀č̣č̣a.ˈ trè,ˈ trè,ˈ ʾə́č̣č̣i-u ʾə̀č̣č̣a.ˈ ʾə̀ṣra,ˈ ʾə̀ṣra,ˈ hàr-ʾəč̣č̣i-u ʾə́č̣č̣a.ˈ klèla,ˈ ʾámər báxta dū̀s-ile.ˈ ʾaláha là-xaləṭ.ˈ ʾə́č̣č̣i-u ʾə̀č̣č̣a,ˈ ʾáxči ʾána max-xšàwti,ˈ ʾáyya kìstaˈ hóle mxožə́bnəlla max-xà.ˈ ha-šqùl,ˈ máttula tămàha.ˈ \n",
      "huðáya l-gàreˈ šwirɛ́le l-pàlga,ˈ yába ʾànən mšúdrəlla!ˈ ʾáy kálba ʾámər táma l-gàre maṣyóθe,ˈ bắyət šaqlə́tla ʾap-ʾànna.ˈ mrázgət gànux.ˈ tə́mməl ṱ-ásqəx kəs-qàzi.ˈ huðáya ʾə́č̣č̣i-u ʾə́č̣č̣a dáwe zìle mə́nne,ˈ ʾɛ́ka ṱ-áθya šə̀nθe?!ˈ hal-qedámta šə́nθe la-θèla.ˈ hár-wele zála-w θàya.ˈ \n",
      "málla múttəlle réše dmìxa.ˈ ṭlìya,ˈ kéfe basìmta,ˈ ʾu-dáwe xo-rèše.ˈ sáʾət ʾə́šta mbàdlaˈ ʾə́θyɛle huðáya wáða ṭəq-ṭəq-ṭə́q l-ṭằra.ˈ ʾu-qáre l-tằraˈ mòdila qə́ṣṣət?ˈ \n",
      "\n",
      "text-trans-full\n",
      "xa'-ga xe`ta,| ma'llah nas.ra`din,| xa'z9x mo`di wi'6a.| gu-b3`8a we'wa,| har-za'la-w 8a`ya.| za'la-w 8a`ya,| ma'ra ya-)a`laha,| yaw9`tli| )9'mma da`we.| )9n-ha`wa| )9'c.>c.>i-u )9'c.>c.>a maq9lb9`nna.| )u-)9n-ha`wa| )9'mma-w-xa`-z>i,| la-ba%y9`nna.| de-s>u`qla.| )9`mma ga%'r9g ha'wa dr9'st.| \n",
      "b-a'laha ho'le za'la-w 8a`ya,| )i'8wale xa'-s>wawa hu6a`ya,| mas.o'8e )9'lle di`ye.| m9're xa'z9x )a'wwa du_`s-ile.| q3'm9n mjarb9`nne.| si'qa l-ga`re,| d9'ry3le )9'c.>c.>i-u )9'c.>c.>a da'we gu-6a-ki`sta,| d9'rya b-ka`wele.| )a' ba'xta ha`yyo!| ho'le )ala'ha q9m-ms>ad9`rr9n.| \n",
      "mu83'83la ma`jma.| msu'rq9lla pi's>ela mna'y9lla l-xa`-xa.| pli'tla )9'c.>c.>i-u )9`c.>c.>a.| tre`,| tre`,| )9'c.>c.>i-u )9`c.>c.>a.| )9`s.ra,| )9`s.ra,| ha`r-)9c.>c.>i-u )9'c.>c.>a.| kle`la,| )a'm9r ba'xta du_`s-ile.| )ala'ha la`-xal9t.| )9'c.>c.>i-u )9`c.>c.>a,| )a'xc>i )a'na max-xs>a`wti,| )a'yya ki`sta| ho'le mxoz>9'bn9lla max-xa`.| ha-s>qu`l,| ma'ttula ta%ma`ha.| \n",
      "hu6a'ya l-ga`re| s>wir3'le l-pa`lga,| ya'ba )a`n9n ms>u'dr9lla!| )a'y ka'lba )a'm9r ta'ma l-ga`re mas.yo'8e,| ba%'y9t s>aql9'tla )ap-)a`nna.| mra'zg9t ga`nux.| t9'mm9l t<-a'sq9x k9s-qa`zi.| hu6a'ya )9'c.>c.>i-u )9'c.>c.>a da'we zi`le m9'nne,| )3'ka t<-a'8ya s>9`n8e?!| hal-qeda'mta s>9'n8e la-8e`la.| ha'r-wele za'la-w 8a`ya.| \n",
      "ma'lla mu'tt9lle re's>e dmi`xa.| tli`ya,| ke'fe basi`mta,| )u-da'we xo-re`s>e.| sa')9t )9's>ta mba`dla| )9'8y3le hu6a'ya wa'6a t9q-t9q-t9'q l-ta%`ra.| )u-qa're l-ta%`ra| mo`dila q9's.s.9t?| \n",
      "\n",
      "text-trans-fuzzy\n",
      "xa-ga xeta, mallah nasradin, xazix modi wida. gu-beta wewa, har-zala-w taya. zala-w taya, mara ya-alaha, yawitli imma dawe. in-hawa i55i-u i55a maqilbinna. u-in-hawa imma-w-xa-zi, la-bayinna. de-suqla. imma garig hawa drist. \n",
      "b-alaha hole zala-w taya, itwale xa-swawa hudaya, masote ille diye. mire xazix awwa dus-ile. qemin mjarbinne. siqa l-gare, diryele i55i-u i55a dawe gu-da-kista, dirya b-kawele. a baxta hayyo! hole alaha qim-msadirrin. \n",
      "mutetela majma. msurqilla pisela mnayilla l-xa-xa. plitla i55i-u i55a. tre, tre, i55i-u i55a. isra, isra, har-i55i-u i55a. klela, amir baxta dus-ile. alaha la-xalit. i55i-u i55a, ax5i ana max-xsawti, ayya kista hole mxozibnilla max-xa. ha-squl, mattula tamaha. \n",
      "hudaya l-gare swirele l-palga, yaba anin msudrilla! ay kalba amir tama l-gare masyote, bayit saqlitla ap-anna. mrazgit ganux. timmil t-asqix kis-qazi. hudaya i55i-u i55a dawe zile minne, eka t-atya sinte?! hal-qedamta sinte la-tela. har-wele zala-w taya. \n",
      "malla muttille rese dmixa. tliya, kefe basimta, u-dawe xo-rese. sait ista mbadla ityele hudaya wada tiq-tiq-tiq l-tara. u-qare l-tara modila qissit? \n",
      "\n",
      "text-trans-lite\n",
      "xa-ga xeta,| mallah naSradin,| xaz9x modi wi6a.| gu-b38a wewa,| har-zala-w 8aya.| zala-w 8aya,| mara ya-)alaha,| yaw9tli| )9mma dawe.| )9n-hawa| )9%%i-u )9%%a maq9lb9nna.| )u-)9n-hawa| )9mma-w-xa-7i,| la-b@y9nna.| de-$uqla.| )9mma g@r9g hawa dr9st.| \n",
      "b-alaha hole zala-w 8aya,| )i8wale xa-$wawa hu6aya,| maSo8e )9lle diye.| m9re xaz9x )awwa dus-ile.| q3m9n mjarb9nne.| siqa l-gare,| d9ry3le )9%%i-u )9%%a dawe gu-6a-kista,| d9rya b-kawele.| )a baxta hayyo!| hole )alaha q9m-m$ad9rr9n.| \n",
      "mu8383la majma.| msurq9lla pi$ela mnay9lla l-xa-xa.| pliTla )9%%i-u )9%%a.| tre,| tre,| )9%%i-u )9%%a.| )9Sra,| )9Sra,| har-)9%%i-u )9%%a.| klela,| )am9r baxta dus-ile.| )alaha la-xal9T.| )9%%i-u )9%%a,| )ax5i )ana max-x$awti,| )ayya kista| hole mxo79bn9lla max-xa.| ha-$qul,| mattula t@maha.| \n",
      "hu6aya l-gare| $wir3le l-palga,| yaba )an9n m$udr9lla!| )ay kalba )am9r tama l-gare maSyo8e,| b@y9t $aql9tla )ap-)anna.| mrazg9t ganux.| t9mm9l +-asq9x k9s-qazi.| hu6aya )9%%i-u )9%%a dawe zile m9nne,| )3ka +-a8ya $9n8e?!| hal-qedamta $9n8e la-8ela.| har-wele zala-w 8aya.| \n",
      "malla mutt9lle re$e dmixa.| Tliya,| kefe basimta,| )u-dawe xo-re$e.| sa)9t )9$ta mbadla| )98y3le hu6aya wa6a T9q-T9q-T9q l-T@ra.| )u-qare l-t@ra| modila q9SS9t?| \n",
      "\n"
     ]
    }
   ],
   "source": [
    "indent(reset=True)\n",
    "info('writing plain text of all texts in all text formats')\n",
    "\n",
    "formats = T.formats\n",
    "\n",
    "text = collections.defaultdict(list)\n",
    "\n",
    "for l in F.otype.s('line'):\n",
    "  for fmt in formats:\n",
    "    text[fmt].append(T.text(l, fmt=fmt, descend=True))\n",
    "\n",
    "info('done {} formats'.format(len(text)))\n",
    "\n",
    "for fmt in sorted(text):\n",
    "    print('{}\\n{}\\n'.format(fmt, '\\n'.join(text[fmt][0:5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The full plain text\n",
    "We write all formats to file, in your `Downloads` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:34.250294Z",
     "start_time": "2018-05-18T09:19:34.156658Z"
    }
   },
   "outputs": [],
   "source": [
    "for fmt in T.formats:\n",
    "  with open(\n",
    "    os.path.expanduser(f'~/Downloads/{fmt}.txt'),\n",
    "    'w',\n",
    "    # encoding='utf8',\n",
    "  ) as f:\n",
    "    f.write('\\n'.join(text[fmt]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(if this errors, uncomment the line with `encoding`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections\n",
    "\n",
    "A section in the NENA corpus is a dialect, a text or a line.\n",
    "Knowledge of sections is not baked into Text-Fabric. \n",
    "The config feature `otext.tf` may specify three section levels, and tell\n",
    "what the corresponding node types and features are.\n",
    "\n",
    "From that knowledge it can construct mappings from nodes to sections, e.g. from line\n",
    "nodes to tuples of the form:\n",
    "\n",
    "    (dialect name, text title, line number)\n",
    "    \n",
    "You can get the section of a node as a tuple of relevant dialect, text, and line nodes.\n",
    "Or you can get it as a passage label, a string.\n",
    "\n",
    "You can ask for the passage corresponding to the first slot of a node, or the one corresponding to the last slot.\n",
    "\n",
    "Here are examples of getting the section that corresponds to a node and vice versa.\n",
    "\n",
    "**NB:** `sectionFromNode` always delivers a line specification, either from the\n",
    "first slot belonging to that node, or, if `lastSlot`, from the last slot\n",
    "belonging to that node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "someNodes = (\n",
    "  F.otype.s('letter')[100000],\n",
    "  F.otype.s('morpheme')[10000],\n",
    "  F.otype.s('word')[5000],\n",
    "  F.otype.s('line')[1000],\n",
    "  F.otype.s('text')[100],\n",
    "  F.otype.s('dialect')[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:43.056511Z",
     "start_time": "2018-05-18T09:19:43.043552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100001 letter   - ((539382, 739666, 575961), (539382, 739666, 575961))\n",
      "    first: Barwar, The Daughter of the King, Ln. 14\n",
      "    last:  Barwar, The Daughter of the King, Ln. 14\n",
      " 587912 morpheme - ((539382, 739651, 575594), (539382, 739651, 575594))\n",
      "    first: Barwar, Gozali and Nozali, Ln. 61\n",
      "    last:  Barwar, Gozali and Nozali, Ln. 61\n",
      " 744771 word     - ((539382, 739651, 575537), (539382, 739651, 575537))\n",
      "    first: Barwar, Gozali and Nozali, Ln. 4\n",
      "    last:  Barwar, Gozali and Nozali, Ln. 4\n",
      " 576368 line     - ((539382, 739686, 576368), (539382, 739686, 576368))\n",
      "    first: Barwar, The Tale of Farxo and Səttiya, Ln. 28\n",
      "    last:  Barwar, The Tale of Farxo and Səttiya, Ln. 28\n",
      " 739745 text     - ((539383, 739745), (539383, 739745, 577524))\n",
      "    first: Urmi_C, The Loan of a Cooking Pot\n",
      "    last:  Urmi_C, The Loan of a Cooking Pot, Ln. 5\n",
      " 539383 dialect  - ((539383,), (539383, 739770, 577911))\n",
      "    first: Urmi_C\n",
      "    last:  Urmi_C, Women Do Things Best, Ln. 19\n"
     ]
    }
   ],
   "source": [
    "for n in someNodes:\n",
    "  nType = F.otype.v(n)\n",
    "  d = f'{n:>7} {nType}'\n",
    "  first = A.sectionStrFromNode(n)\n",
    "  last = A.sectionStrFromNode(n, lastSlot=True, fillup=True)\n",
    "  tup = (\n",
    "      T.sectionTuple(n),\n",
    "      T.sectionTuple(n, lastSlot=True, fillup=True),\n",
    "  )\n",
    "  print(f'{d:<16} - {tup}')\n",
    "  print(f'    first: {first}')\n",
    "  print(f'    last:  {last}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean caches\n",
    "\n",
    "Text-Fabric pre-computes data for you, so that it can be loaded faster.\n",
    "If the original data is updated, Text-Fabric detects it, and will recompute that data.\n",
    "\n",
    "But there are cases, when the algorithms of Text-Fabric have changed, without any changes in the data, that you might\n",
    "want to clear the cache of precomputed results.\n",
    "\n",
    "There are two ways to do that:\n",
    "\n",
    "* Locate the `.tf` directory of your dataset, and remove all `.tfx` files in it.\n",
    "  This might be a bit awkward to do, because the `.tf` directory is hidden on Unix-like systems.\n",
    "* Call `TF.clearCache()`, which does exactly the same.\n",
    "\n",
    "It is not handy to execute the following cell all the time, that's why I have commented it out.\n",
    "So if you really want to clear the cache, remove the comment sign below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TF.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "By now you have an impression how to compute around in the corpus.\n",
    "While this is still the beginning, I hope you already sense the power of unlimited programmatic access\n",
    "to all the bits and bytes in the data set.\n",
    "\n",
    "Here are a few directions for unleashing that power.\n",
    "\n",
    "* **[display](display.ipynb)** become an expert in creating pretty displays of your text structures\n",
    "* **[search](search.ipynb)** turbo charge your hand-coding with search templates\n",
    "* **[exportExcel](exportExcel.ipynb)** make tailor-made spreadsheets out of your results\n",
    "* **[share](share.ipynb)** draw in other people's data and let them use yours\n",
    "* **[similarLines](similarLines.ipynb)** spot the similarities between lines\n",
    "\n",
    "---\n",
    "\n",
    "See the [cookbook](cookbook) for recipes for small, concrete tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
