{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "It is assumed that you have read\n",
    "[start](start.ipynb)\n",
    "and followed the installation instructions there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "This is\n",
    "\n",
    "* `quran` Q'uran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First acquaintance\n",
    "\n",
    "We just want to grasp what the corpus is about and how we can find our way in the data.\n",
    "\n",
    "Open a terminal or command prompt and say one of the following\n",
    "\n",
    "```text-fabric quran```\n",
    "\n",
    "Wait and see a lot happening before your browser starts up and shows you an interface on the corpus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text-Fabric needs an app to deal with the corpus-specific things.\n",
    "It downloads/finds/caches the latest version of the **app**:\n",
    "\n",
    "```\n",
    "Using TF-app in /Users/dirk/text-fabric-data/annotation/app-quran/code:\n",
    "\t#c55d75da760bfdc6ae272b3ade9629fe34d059ce (latest commit)\n",
    "```\n",
    "\n",
    "It downloads/finds/caches the latest version of the **data**:\n",
    "\n",
    "```\n",
    "Using data in /Users/dirk/text-fabric-data/q-ran/quran/tf/0.4:\n",
    "\trv0.5=#60bd6788dadb13974e89df55cde7687c0593e65f (latest release)\n",
    "```\n",
    "\n",
    "The data is preprocessed in order to speed up typical Text-Fabric operations.\n",
    "The result is cached on your computer.\n",
    "Preprocessing costs time. Next time you use this corpus on this machine, the startup time is much quicker.\n",
    "\n",
    "```\n",
    "TF setup done.\n",
    "```\n",
    "\n",
    "Then the app goes on to act as a local webserver serving the corpus that has just been downloaded\n",
    "and it will open your browser for you and load the corpus page\n",
    "\n",
    "```\n",
    " * Running on http://localhost:8105/ (Press CTRL+C to quit)\n",
    "Opening quran in browser\n",
    "Listening at port 18985\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/q-bare.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help!\n",
    "\n",
    "Indeed, that is what you need. Click the vertical `Help` tab.\n",
    "\n",
    "From there, click around a little bit. Don't read closely, just note the kinds of information that is presented to you.\n",
    "\n",
    "Later on, it will make more sense!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Browsing\n",
    "\n",
    "First we browse our data. Click the browse button.\n",
    "\n",
    "<img src=\"images/q-browse.png\" width=\"800\">\n",
    "\n",
    "and then, in the table of *documents* (suras), click on one.\n",
    "\n",
    "<img src=\"images/q-documents.png\" width=\"200\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're looking at the ayas of a sura: the marks in an Arabic unicode  characters.\n",
    "\n",
    "<img src=\"images/q-sura.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now click the *Options* tab and select the `text-trans-full` format to see the sura tablet in ascii transcription.\n",
    "\n",
    "<img src=\"images/q-ascii.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can click a triangle to see how a line is broken down:\n",
    "\n",
    "<img src=\"images/q-drill.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching\n",
    "\n",
    "An  aya is a verse in a  sura.\n",
    "Let's find all the ayas that contain a verb followed by the word for Allah.\n",
    "\n",
    "Enter this query in the search pad and press the search icon above it.\n",
    "\n",
    "```\n",
    "aya\n",
    "  word pos=verb\n",
    "  <: word pos=noun    \n",
    "          posx=proper\n",
    "          root=Alh\n",
    "```\n",
    "\n",
    "<img src=\"images/q-search.png\" width=\"1200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In English:\n",
    "\n",
    "search all `aya`s that contain a `word` and a `word`  where:\n",
    "\n",
    "* `<:` the second `word` follows immediately on the first `word`\n",
    "* the first `word` has value `verb`  for feature `pos` (part-of-speech)\n",
    "* the second `word` has\n",
    "  * value `noun`  for feature `pos`\n",
    "  * value `proper` for feature `posx` (subcategorisation of part-of-speech)\n",
    "  * value `Alh` for feature `root` (basic word form, more fundamental than lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can expand results by clicking the triangle. \n",
    "\n",
    "You can see the result in context by  clicking the browse icon.\n",
    "\n",
    "You can go back to the result list by clicking the results icon.\n",
    "\n",
    "<img src=\"images/q-back.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corpus has a feature for ayas in which an English translation is given: `translation@en`.\n",
    "\n",
    "We can trigger the display of these translations by mentioning the feature in the query without posing additional constraints:\n",
    "\n",
    "```\n",
    "aya translation@en*\n",
    "  word pos=verb\n",
    "  <: word pos=noun    \n",
    "          posx=proper\n",
    "          root=Alh\n",
    "```\n",
    "\n",
    "The `*` means: any value or even no value.\n",
    "\n",
    "<img src=\"images/q-search2.png\" width=\"1200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing\n",
    "\n",
    "We have found verbs associated with Allah.\n",
    "\n",
    "The question comes to mind: are there verbs that are associated with Allah only in this way?\n",
    "\n",
    "Let us look for verbs, followed by nouns, and for each verb, count how many different nouns occur in that position.\n",
    "\n",
    "*This is a typical question where you want to leave the search mode and enter computing mode*.\n",
    "\n",
    "Let's do that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have followed the installation instructions, you are set.\n",
    "Go to the browser window that opened when you gave the command `jupyter notebook` in your terminal.\n",
    "\n",
    "Then continue reading, and, ... executing.\n",
    "\n",
    "You can execute a cell by putting your cursor inside it and pressing `Shift Enter`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the Text-Fabric module, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.app import use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the TF-app for the corpus `quran` and that app loads the corpus data.\n",
    "\n",
    "We give a name to the result of all that loading: `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = use('quran', hoist=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some bits are familiar from above, when you ran the `text-fabric` command in the terminal.\n",
    "\n",
    "Other bits are links to the documentation, they point to the same places as the links on the Text-Fabric browser.\n",
    "\n",
    "You see a list of all the data features that have been loaded.\n",
    "\n",
    "And a list of references to the API documentation, which tells you how you can use this data in your program statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching (revisited)\n",
    "\n",
    "We do the same search again, but now inside our program.\n",
    "\n",
    "That means that we can capture the results in a list for further processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = A.search('''\n",
    "aya\n",
    "  word pos=verb\n",
    "  <: word pos=noun    \n",
    "          posx=proper\n",
    "          root=Alh\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In less than a second, we have all the results!\n",
    "\n",
    "Let's look at the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each result is a list of numbers: for a \n",
    "\n",
    "1. aya\n",
    "1. word\n",
    "1. word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the  second one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here the last one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we modify the query to get all pairs of proper verbs followed by a proper noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = A.search('''\n",
    "aya\n",
    "  word pos=verb\n",
    "  <: word pos=noun    \n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to make buckets for the root of each verb found, and in those buckets we throw the roots of all nouns found after them. \n",
    "We also count the number of occurrences of each noun root in the buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = collections.defaultdict(collections.Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (aya, verb, noun) in results:\n",
    "  buckets[F.root.v(verb)][F.root.v(noun)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many buckets do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many nouns are there in each bucket?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(len(nouns) for (bucket, nouns) in buckets.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(len(nouns) for (bucket, nouns)  in buckets.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get a picture of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(color_codes=True)\n",
    "sns.distplot(list(len(nouns) for nouns in buckets.values()), axlabel=\"number of nouns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collect the buckets of length 1 in two sets: those with Allah in the bucket and those with another word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets1A = {bucket for (bucket, nouns) in buckets.items() if len(nouns) == 1 and 'Alh' in nouns}\n",
    "buckets1N = {bucket for (bucket, nouns) in buckets.items() if len(nouns) == 1 and 'Alh' not in nouns}\n",
    "print(f\"with    Alh: {len(buckets1A):>3}\")\n",
    "print(f\"without Alh: {len(buckets1N):>3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we show the roots of the verbs that are associated only with `Alh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(buckets1A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we want to find them back in the text and show the translations of the ayas they contain.\n",
    "\n",
    "We compute a query out of the `bucket1A` contents, and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = '|'.join(buckets1A)\n",
    "condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "aya\n",
    "  word pos=verb\n",
    "       root={condition}\n",
    "  <: word pos=noun    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = A.search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can show the results quite easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.table(results, end=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the results in transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.table(results, end=10, fmt='text-trans-full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better, we have a transcription that only shows the roots of the words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.table(results, end=10, fmt='root-trans-full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we wanted the translations of the relevant ayas. Here they come:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (aya, verb, noun) in results:\n",
    "  print(Fs('translation@en').v(aya))\n",
    "  print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
